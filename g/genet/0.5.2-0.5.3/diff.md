# Comparing `tmp/genet-0.5.2-py3-none-any.whl.zip` & `tmp/genet-0.5.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,21 @@
-Zip file size: 31910 bytes, number of entries: 39
+Zip file size: 37723 bytes, number of entries: 39
 -rw-rw-rw-  2.0 fat      109 b- defN 22-Oct-28 02:23 genet/__init__.py
--rw-rw-rw-  2.0 fat       74 b- defN 22-Oct-28 02:23 genet/genet_print.py
--rw-rw-rw-  2.0 fat       35 b- defN 22-Oct-28 02:23 genet/main.py
+-rw-rw-rw-  2.0 fat      113 b- defN 22-Dec-29 12:57 genet/main.py
 -rw-rw-rw-  2.0 fat      102 b- defN 22-Dec-21 12:42 genet/analysis/__init__.py
 -rw-rw-rw-  2.0 fat    10745 b- defN 22-Dec-24 07:17 genet/analysis/functional.py
 -rw-rw-rw-  2.0 fat      229 b- defN 22-Nov-23 01:16 genet/database/__init__.py
--rw-rw-rw-  2.0 fat     8425 b- defN 22-Dec-05 05:22 genet/database/functional.py
--rw-rw-rw-  2.0 fat       61 b- defN 22-Nov-23 05:19 genet/design/__init__.py
--rw-rw-rw-  2.0 fat    15730 b- defN 22-Dec-22 05:03 genet/design/functional.py
+-rw-rw-rw-  2.0 fat     8457 b- defN 23-Feb-01 08:54 genet/database/functional.py
+-rw-rw-rw-  2.0 fat     3275 b- defN 23-May-23 03:59 genet/design/DesignUtils.py
+-rw-rw-rw-  2.0 fat      101 b- defN 23-May-23 04:02 genet/design/__init__.py
+-rw-rw-rw-  2.0 fat    37661 b- defN 23-May-23 04:10 genet/design/functional.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 02:23 genet/design/ref_transcripts.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 02:23 genet/design/modules/__init__.py
 -rw-rw-rw-  2.0 fat      172 b- defN 22-Nov-24 08:57 genet/predict/__init__.py
--rw-rw-rw-  2.0 fat    39119 b- defN 22-Dec-05 04:06 genet/predict/functional.py
+-rw-rw-rw-  2.0 fat    44443 b- defN 23-May-02 11:10 genet/predict/functional.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 05:54 genet/predict/models/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 06:25 genet/predict/models/DeepBaseEditor/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 06:11 genet/predict/models/DeepPrime/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 06:24 genet/predict/models/DeepPrime/DeepPrime_FT/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 06:24 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_293T_NRCH_PE2/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_293T_NRCH_PE2max/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_293T_PE2_Conv/__init__.py
@@ -26,16 +26,16 @@
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_DLD1_PE4max/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_HCT116_PE2/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_HeLa_PE2max/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_MDA_PE2/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-31 01:05 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_NIH_NRCH_PE4max/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 06:11 genet/predict/models/DeepPrime/DeepPrime_base/__init__.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Oct-28 05:54 genet/predict/models/DeepSpCas9/__init__.py
--rw-rw-rw-  2.0 fat      180 b- defN 22-Dec-24 07:21 genet/utils/__init__.py
+-rw-rw-rw-  2.0 fat      180 b- defN 23-May-23 04:07 genet/utils/__init__.py
 -rw-rw-rw-  2.0 fat     1737 b- defN 22-Dec-23 11:59 genet/utils/functional.py
 -rw-rw-rw-  2.0 fat       43 b- defN 22-Oct-28 02:23 tests/__init__.py
--rw-rw-rw-  2.0 fat    14041 b- defN 22-Dec-24 07:21 genet-0.5.2.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 22-Dec-24 07:21 genet-0.5.2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat      112 b- defN 22-Dec-24 07:21 genet-0.5.2.dist-info/dependency_links.txt
--rw-rw-rw-  2.0 fat       12 b- defN 22-Dec-24 07:21 genet-0.5.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     3798 b- defN 22-Dec-24 07:21 genet-0.5.2.dist-info/RECORD
-39 files, 94816 bytes uncompressed, 25518 bytes compressed:  73.1%
+-rw-rw-rw-  2.0 fat    14092 b- defN 23-May-23 04:13 genet-0.5.3.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-May-23 04:13 genet-0.5.3.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat      112 b- defN 23-May-23 04:13 genet-0.5.3.dist-info/dependency_links.txt
+-rw-rw-rw-  2.0 fat       12 b- defN 23-May-23 04:13 genet-0.5.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     3809 b- defN 23-May-23 04:13 genet-0.5.3.dist-info/RECORD
+39 files, 125484 bytes uncompressed, 31317 bytes compressed:  75.0%
```

## zipnote {}

```diff
@@ -1,13 +1,10 @@
 Filename: genet/__init__.py
 Comment: 
 
-Filename: genet/genet_print.py
-Comment: 
-
 Filename: genet/main.py
 Comment: 
 
 Filename: genet/analysis/__init__.py
 Comment: 
 
 Filename: genet/analysis/functional.py
@@ -15,14 +12,17 @@
 
 Filename: genet/database/__init__.py
 Comment: 
 
 Filename: genet/database/functional.py
 Comment: 
 
+Filename: genet/design/DesignUtils.py
+Comment: 
+
 Filename: genet/design/__init__.py
 Comment: 
 
 Filename: genet/design/functional.py
 Comment: 
 
 Filename: genet/design/ref_transcripts.py
@@ -96,23 +96,23 @@
 
 Filename: genet/utils/functional.py
 Comment: 
 
 Filename: tests/__init__.py
 Comment: 
 
-Filename: genet-0.5.2.dist-info/METADATA
+Filename: genet-0.5.3.dist-info/METADATA
 Comment: 
 
-Filename: genet-0.5.2.dist-info/WHEEL
+Filename: genet-0.5.3.dist-info/WHEEL
 Comment: 
 
-Filename: genet-0.5.2.dist-info/dependency_links.txt
+Filename: genet-0.5.3.dist-info/dependency_links.txt
 Comment: 
 
-Filename: genet-0.5.2.dist-info/top_level.txt
+Filename: genet-0.5.3.dist-info/top_level.txt
 Comment: 
 
-Filename: genet-0.5.2.dist-info/RECORD
+Filename: genet-0.5.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## genet/main.py

```diff
@@ -1,3 +1,6 @@
 import analysis as a
+import predict as prd
 
-a.loadseq()
+a.loadseq()
+
+print('This is test commit for testing git branch')
```

## genet/database/functional.py

```diff
@@ -1,11 +1,15 @@
 import os, sys
 import genet.utils
 from Bio import Entrez, GenBank, SeqIO
 
+'''
+Branch test 221230
+'''
+
 class GetGene:
     '''
     NCBI에서 reference gene을 찾기 위한 함수.
     기본적으로 biopython의 Entrez module과 GenBank module을 사용한다. 
 
     default는 human genome에서 reference gene sequence를 가져오는 것이다. \n
     하지만 만약 사용자가 다른 sequence 정보를 가져오고 싶다면,\n
```

## genet/design/__init__.py

```diff
@@ -1,2 +1,3 @@
 from .modules import *
-from genet.design.functional import *
+from genet.design.functional import *
+from genet.design.DesignUtils import *
```

## genet/design/functional.py

```diff
@@ -1,12 +1,15 @@
 # from genet.utils import *
 import os, sys, regex
 import genet.utils
 import pandas as pd
-from Bio import Entrez, GenBank, SeqIO
+from Bio import Entrez, GenBank
+from Bio.Seq import reverse_complement, translate
+from Bio.SeqUtils import GC
+from genet.design.DesignUtils import dict_pam_disrup_rank, test_score_data
 
 '''
 TODO
 1. flash를 python code로 구현한 것이 없으므로, 여기서 input은 .fastq 파일만 가능
 2. 나중에 flashpy 개발이 좀 더 진행되면 도입하는 것을 생각해보자
 3. python 기본적으로 python 3.6~3.10까지 호환되는 것을 목표로 하고, 3.11도 테스트하기
 
@@ -37,30 +40,500 @@
 
 
 # class END: MakeStop
 
 
 
 class MakeSNVs:
-    '''MakeSNVs
-    특정 spacis, chromosome, location을 정해주면 해당 범위 내에 모든 SNV saturation WT / ED sequence pair를 return 해주는 class.
-    SNV saturation library를 제작하거나, 특정 범위 내에 어디든 상관 없이 가장 base or prime editing 이 잘 되는 곳을 찾기 위해 필요한 함수
-    
-    #### Example
-    >>> from genet.design import MakeSNVs
-    >>> df_snvs = MakeSNVs(chr=13, start=1704029, end=1704100)
-    '''
 
-    def __init__(self, chr:int, start:int, end:int, species:str='homo sapiens'):
-        print('Start MakeSNVs')
+    def __init__(self, seq:str, pos:int) -> list:
+        """sequence에서 지정된 위치에 A/T/G/C로 만들어진 SNV를 만들어서 list로 return하는 함수
 
+        Args:
+            seq (str): SNV를 만들 서열 정보
+            pos (int): seq에서 SNV를 만들 위치 정보
+
+        Returns:
+            list: 특정 위치에 가능한 SNV들이 모인 list
+
+        Eaxmple
+            >>> from genet.design import MakeSNVs
+            >>> seq = 'ATGGCTGACTGC'
+            >>> list_snvs = MakeSNVs(seq, 4)
+
+            list_snvs = ['ATGGATGACTGC', 'ATGGGTGACTGC', 'ATGGTTGACTGC']
+        """        
+
+        list_base = ['A', 'G', 'C', 'T']
+        self.list_sSNV = []
+
+        for base in list_base:
+            list_sSeq = list(seq)
+            list_sSeq[pos] = base
+            snv_temp = ''.join(list_sSeq)
+            if seq!=snv_temp: self.list_sSNV.append(snv_temp)
 
+# class END: MakeSNVs
 
+class SynonymousPE:
+
+    def __init__(self,
+                 dp_record:pd.Series,
+                 ref_seq:str,
+                 frame:int,
+                 cds_start:int=0,
+                 cds_end:int=121,
+                 adj_rha:bool=True,
+                 ):
+        """DeepPrime output으로 만들어진 파일에서 pegRNA들에 silent mutation을 함께 유발하는 것 중 최적의 pegRNA를 선택해주는 것
+        모든 기능은 prime editing으로 1bp substitution을 했을 때를 가정하여 만들어졌다.
+        우선, intended edit 기준으로 best pegRNA들을 선정한다.
+        그 후, 아래와 같이 silent PAM co-editing을 추가한다.
+
+        Case 1: Silent PAM co-editing이 LHA 부분에 발생하는 경우,
+        그대로 silent PAM co-editing을 넣고 완성
+
+        Case 2: Silent PAM co-editing이 RHA 부분에 발생하는 경우,
+        원래 pegRNA의 RHA 길이를 기준으로 맞춰주기 위해 RTT 길이를 늘려주기.
+        
+        Case 3: Intended edit이 이미 PAM 위치 (+5 or +6)인 경우,
+        1) 만약 남은 PAM 위치 (G)에 silent mutation이 가능하면 그 것으로 결정
+        2) 남은 PAM 위치의 SNV 중 silent mutation이 없다면, LHA에서 가능한 silent mutation을 넣어준다.
+        3) 만약 선택되는 mutation position이 splicing adaptor 위치라면, (cds_start / end 앞뒤로 5nt) 차순위로 뽑기
+        4) 차순위로 불가능한 것들이 있다면, RHA에서 silent mutation을 뽑는다.         
+
+        Args:
+            dp_record (pd.Series): DeepPrime을 돌리고 output으로 나오는 것의 한 index의 정보를 가져온 것
+            ref_seq (str): 해당 mutation을 만들었을 떄, 사용한 reference sequence (121nt)
+            frame (int): Ref_seq의 frame을 표시 (0, 1, 2)
+            cds_start (int, optional): CDS가 시작되는 위치, 그 이전 위치에서부터는 silent mutation을 만들 수 없으므로 고르는 위치에서 제외. Defaults to 0.
+            cds_end (int, optional): CDS가 종료되는 위치, 그 이후 위치에서부터는 silent mutation을 만들 수 없으므로 고르는 위치에서 제외. Defaults to 121.
+            adj_rha (bool, optional): silent mutation이 RHA에 위치하는 경우, 기존의 pegRNA에서의 RHA 길이만큼을 유지하기 위해 RTT를 늘려주는 기능. Defaults to True.
+
+        Raises:
+            ValueError: frame이 0, 1, 2 중에 하나로 입력되지 않은 경우
+            ValueError: Reference sequence가 pegRNA와 matching이 안 될 경우
+        """        
+    
+        # input error check
+
+        if type(dp_record) != type(pd.Series()): raise TypeError("The type of 'dp_record' should be pd.Series.")
+        if frame not in [0, 1, 2]              : raise ValueError('Frame should be 0, 1 or 2')
+
+        # step 1: 각종 서열 정보들을 가져온다.
+
+        self.sID      = dp_record.ID
+        self.wt_seq   = dp_record.WT74_On
+        self.pbs_dna  = dp_record.Edited74_On.replace('x', '')[:dp_record.PBSlen]
+        self.rtt_dna  = dp_record.Edited74_On.replace('x', '')[-dp_record.RTlen:]
+        self.edit_pos = dp_record.Edit_pos
+        self.ref_seq  = ref_seq.upper()
+
+        # step 2: pegRNA의 strand 방향에 따라 synonymous Mut 생성 함수 결정
+        
+        if self.wt_seq in self.ref_seq:
+            self.strand = '+'
+            self.rtt_frame = (frame - self.edit_pos + 1) % 3 # rtt 시작점의 frame, LHA 길이를 이용한 계산
+            self.output = self.make_synonyPAM_RTT_fwd(self.rtt_frame, self.rtt_dna, self.strand) # edit position / Silent mut 고려해서 뽑은 것들
+
+        elif reverse_complement(self.wt_seq) in self.ref_seq:
+            self.strand = '-'
+            self.rtt_frame = (self.edit_pos + frame) % 3  # revcom_rtt_dna의 3' end가 위치하는 지점의 frame. 시작점이 거기이기 때문.
+            self.output = self.make_synonyPAM_RTT_rev(self.rtt_frame, self.rtt_dna, self.strand) # edit position / Silent mut 고려해서 뽑은 것들
+            
+        else: raise ValueError('Reference sequence is not matched with pegRNA information!\nPlease chech your ref_seq')
+        
+        # step 3: 만약 RHA 길이 조정 옵션이 True로 되어있으면, 조정해주기. (defualt)
+
+        if adj_rha == True:
+            adj_len = self.output['Mut_pos'] - self.edit_pos
+            
+            if adj_len > 0: 
+                rtt_end = 21 + dp_record.RTlen
+                self.output['RTT_DNA_Mut'] = self.output['RTT_DNA_Mut'] + self.wt_seq[rtt_end:rtt_end+adj_len]
+
+        self.extension = self.pbs_dna + self.output['RTT_DNA_Mut']
+        
+    # End def __init__:
+        
+
+        
+    def make_snv(self, seq:str, pos:int) -> list:
+        """sequence에서 지정된 위치에 A/T/G/C로 만들어진 SNV를 만들어서 list로 return하는 함수
+
+        Args:
+            seq (str): SNV를 만들 서열 정보
+            pos (int): seq에서 SNV를 만들 위치 정보
+
+        Returns:
+            list: 특정 위치에 가능한 SNV들이 모인 list
+        """        
+
+        list_base = ['A', 'G', 'C', 'T']
+        list_sSNV = []
+
+        for base in list_base:
+            list_sSeq = list(seq)
+            list_sSeq[pos] = base
+            snv_temp = ''.join(list_sSeq)
+            if seq!=snv_temp: list_sSNV.append(snv_temp)
+
+        return list_sSNV
+    # def END: make_snv
+
+    def make_dict_codon_pamPos(self, strand:str, rtt_frame:int, rtt_dna:str) -> dict:
+        """_summary_
+
+        Args:
+            strand (str): _description_
+            rtt_frame (int): _description_
+            rtt_dna (str): _description_
+
+        Returns:
+            dict: _description_
+        """       
+
+        if strand == '+':
+            if   rtt_frame == 0: dict_codon_pamPos = {rtt_dna[3:6]: [1, 2]}
+            elif rtt_frame == 1: dict_codon_pamPos = {rtt_dna[2:5]: [2]}
+            else               : dict_codon_pamPos = {rtt_dna[4:7]: [0, 1]}
+
+        
+        else:
+            # strand가 (-)인 경우에는 RT-PBS를 revcom으로 바꿔서 PAM 기준으로 SNV들을 만들기
+            rc_rtt_dna = reverse_complement(rtt_dna)
+            if   rtt_frame == 0: dict_codon_pamPos = {rc_rtt_dna[-6:-3]: [0, 1]}
+            elif rtt_frame == 1: dict_codon_pamPos = {rc_rtt_dna[-7:-4]: [1, 2]}
+            else               : dict_codon_pamPos = {rc_rtt_dna[-8:-5]: [2], rc_rtt_dna[-5:-2]: [0]}
+
+        return dict_codon_pamPos
+    
+
+    
+    def make_synonyPAM_RTT_fwd(self, rtt_frame:int, rtt_dna:str, strand:str) -> pd.DataFrame:
+        """pegRNA가 CDS strand 방향과 동일한 경우 (+)
+        PAM sequence (GG)에서 frame에 따라 가능한 synonymous mutation들을 만들고,
+        이에 대한 결과를 DataFrame으로 만들어준다. 
+
+        Args:
+            rtt_frame (int): CDS에서 RTT의 frame을 의미함 (0, 1, 2).
+            rtt_dna (str): pegRNA의 RTT 부분을 DNA로 가져온 것. cDNA와 동일.
+            strand (str): Reference sequence 기준으로 pegRNA의 방향 (+ / -)
+
+        Returns:
+            pd.DataFrame: PAM 위치에 가능한 synonymous mutation 정보들
+        """   
+        
+        dict_codon_pamPos = self.make_dict_codon_pamPos(strand, rtt_frame, rtt_dna)
+    
+        self.dict_mut = {
+            'Codon_WT'      : [],
+            'Codon_Mut'     : [],
+            'RTT_DNA_frame' : [],
+            'RTT_DNA_Strand': [],
+            'AminoAcid_WT'  : [],
+            'AminoAcid_Mut' : [],
+            'Silent_check'  : [],
+            'Mut_pos'       : [],
+            'PAM_Mut'       : [],
+            'Priority'      : [],
+            'Edit_class'    : [],
+            'RTT_DNA_Mut'   : [],
+        }
+
+        if strand == '+': PAM_G_pos = 5
+        else            : PAM_G_pos = 6
+        
+        # for loop: GG PAM 위치가 걸쳐있는 codon들을 가져온다.
+        for codon in dict_codon_pamPos:
+            # for loop: 각 codon들에서 GG PAM에 해당하는 위치들을 가져온다.
+            for snv_pos in dict_codon_pamPos[codon]:
+                
+                # list_mut_codon = self.make_snv(codon, snv_pos)
+                list_mut_codon = MakeSNVs(codon, snv_pos).list_sSNV
+                
+                for mut_codon in list_mut_codon:
+                    
+                    aa_wt  = translate(codon)
+                    aa_mut = translate(mut_codon)
+                    
+                    self.dict_mut['Codon_WT'].append(codon)
+                    self.dict_mut['Codon_Mut'].append(mut_codon)
+                    self.dict_mut['RTT_DNA_frame'].append(rtt_frame)
+                    self.dict_mut['RTT_DNA_Strand'].append(strand)
+                    self.dict_mut['AminoAcid_WT'].append(aa_wt)
+                    self.dict_mut['AminoAcid_Mut'].append(aa_mut)
+                    self.dict_mut['Silent_check'].append(aa_wt==aa_mut)
+                    self.dict_mut['Mut_pos'].append(PAM_G_pos)
+                    
+                    if strand == '+':
+                        if PAM_G_pos == 5: pam_mut = mut_codon[snv_pos] + self.rtt_dna[5]
+                        else             : pam_mut = self.rtt_dna[4] + mut_codon[snv_pos]
+                    else:
+                        if PAM_G_pos == 6: pam_mut = self.rtt_dna[4] + reverse_complement(mut_codon[snv_pos])
+                        else             : pam_mut = reverse_complement(mut_codon[snv_pos]) + self.rtt_dna[5]
+                        
+                    if strand == '+':
+                        if   rtt_frame == 0: rtt_dna_mut = self.rtt_dna[:3] + mut_codon + self.rtt_dna[6:]
+                        elif rtt_frame == 1: rtt_dna_mut = self.rtt_dna[:5] + mut_codon + self.rtt_dna[8:]
+                        else               : rtt_dna_mut = self.rtt_dna[:4] + mut_codon + self.rtt_dna[7:]
+
+                    else:
+                        print('Strand 합치기 위한 작업 해야 함.')
+
+
+                    self.dict_mut['PAM_Mut'].append(pam_mut)
+                    self.dict_mut['Priority'].append(dict_pam_disrup_rank[pam_mut])
+                    self.dict_mut['RTT_DNA_Mut'].append(rtt_dna_mut)
+                    self.dict_mut['Edit_class'].append('PAM_edit')
+                    
+                PAM_G_pos += 1
+                    
+        self.mutations  = pd.DataFrame(self.dict_mut) 
+
+        try:
+            df_synonymous = self.mutations.groupby(by='Silent_check').get_group(True).sort_values(by='Priority').reset_index(drop=True)
+            df_synonymous = df_synonymous[df_synonymous['Mut_pos'] != self.edit_pos]
+
+            return df_synonymous.iloc[0]
+
+        except:
+            df_synonymous = self.make_synonyLHA_fwd(self.rtt_dna, rtt_frame, strand)
+
+            return df_synonymous.iloc[0]
+
+    # def END: make_synonymousPAM_RTT_fwd
+    
+    def make_synonyPAM_RTT_rev(self, rtt_frame:int, rtt_dna:str, strand:str) -> pd.DataFrame:
+        """pegRNA가 CDS strand 방향과 반대인 경우 (-)
+        우선 RTT_DNA sequence를 reverse complementary sequence로 가져온 다음
+        PAM sequence (CC)에서 frame에 따라 가능한 synonymous mutation들을 만들고,
+        이에 대한 결과를 DataFrame으로 만들어준다. 
+
+        Args:
+            rtt_frame (int): CDS에서 RTT의 frame을 의미함 (0, 1, 2).
+            rtt_dna (str): pegRNA의 RTT 부분을 DNA로 가져온 것. cDNA와 동일.
+            strand (str): Reference sequence 기준으로 pegRNA의 방향 (+ / -)
+
+        Returns:
+            pd.DataFrame: PAM 위치에 가능한 synonymous mutation 정보들
+        """        
+
+        # strand가 (-)인 경우에는 RT-PBS를 revcom으로 바꿔서 PAM 기준으로 SNV들을 만들기
+        
+        rc_rtt_dna = reverse_complement(rtt_dna)
+        
+        if   rtt_frame == 0: dict_codon_pamPos = {rc_rtt_dna[-6:-3]: [0, 1]}
+        elif rtt_frame == 1: dict_codon_pamPos = {rc_rtt_dna[-7:-4]: [1, 2]}
+        else               : dict_codon_pamPos = {rc_rtt_dna[-8:-5]: [2], rc_rtt_dna[-5:-2]: [0]}
+
+        self.dict_mut = {
+            'Codon_WT'      : [],
+            'Codon_Mut'     : [],
+            'RTT_DNA_frame' : [],
+            'RTT_DNA_Strand': [],
+            'AminoAcid_WT'  : [],
+            'AminoAcid_Mut' : [],
+            'Silent_check'  : [],
+            'Mut_pos'       : [],
+            'PAM_Mut'       : [],
+            'Priority'      : [],
+            'Edit_class'    : [],
+            'RTT_DNA_Mut'   : [],
+        }
+
+        PAM_G_pos = 6
+        
+        # for loop: GG PAM 위치가 걸쳐있는 codon들을 가져온다.
+        for codon in dict_codon_pamPos:
+            # for loop: 각 codon들에서 GG PAM에 해당하는 위치들을 가져온다.
+            for snv_pos in dict_codon_pamPos[codon]:
+                
+                list_mut_codon = self.make_snv(codon, snv_pos)
+                
+                for mut_codon in list_mut_codon:
+                    
+                    aa_wt  = translate(codon)
+                    aa_mut = translate(mut_codon)
+                    
+                    self.dict_mut['Codon_WT'].append(codon)
+                    self.dict_mut['Codon_Mut'].append(mut_codon)
+                    self.dict_mut['RTT_DNA_frame'].append(rtt_frame)
+                    self.dict_mut['RTT_DNA_Strand'].append(strand)
+                    self.dict_mut['AminoAcid_WT'].append(aa_wt)
+                    self.dict_mut['AminoAcid_Mut'].append(aa_mut)
+                    self.dict_mut['Silent_check'].append(aa_wt==aa_mut)
+                    self.dict_mut['Mut_pos'].append(PAM_G_pos)
+                    
+                    if PAM_G_pos == 6: pam_mut = self.rtt_dna[4] + reverse_complement(mut_codon[snv_pos])
+                    else             : pam_mut = reverse_complement(mut_codon[snv_pos]) + self.rtt_dna[5]
+                        
+                    self.dict_mut['PAM_Mut'].append(pam_mut)
+                    self.dict_mut['Priority'].append(dict_pam_disrup_rank[pam_mut])
+                    
+                    rtt_dna_mut = self.rtt_dna[:4] + reverse_complement(mut_codon) + self.rtt_dna[7:]
+
+                    self.dict_mut['RTT_DNA_Mut'].append(rtt_dna_mut)
+                    self.dict_mut['Edit_class'].append('PAM_edit')
+                    
+                PAM_G_pos -= 1
+
+        self.mutations  = pd.DataFrame(self.dict_mut) 
+        
+        try:
+            df_synonymous = self.mutations.groupby(by='Silent_check').get_group(True).sort_values(by='Priority').reset_index(drop=True)
+            df_synonymous = df_synonymous[df_synonymous['Mut_pos'] != self.edit_pos]
+
+            # 만약 edit pos가 이미 PAM을 targeting 하고 있는 등의 이유로, 뽑히는 PAM silent Mut이 없다면, LHA에서 뽑기
+            # if len(self.output) == 0: df_synonymous = self.make_synonyLHA_rev(self.rtt_dna, rtt_frame, strand)
+            
+            return df_synonymous.iloc[0]
+
+        except:
+            df_synonymous = self.make_synonyLHA_rev(self.rtt_dna, rtt_frame, strand)
+
+            return df_synonymous.iloc[0]
+
+               
+    # def END: make_synonymousPAM_RTT_rev
+
+        
+    def make_synonyLHA_fwd(self, rtt_dna:str, rtt_frame:int, strand:str) -> pd.DataFrame:
+        """만약 PAM synonymous mutation이 불가능한 경우,
+        silent mutation은 LHA에 만들어주는 함수
+        그 중, strand 방향이 (+)인 경우에 대한 함수이다. 
+
+        Returns:
+            pd.DataFrame: _description_
+        """        
+
+        ep = self.edit_pos
+
+        codon_le  = rtt_frame
+        codon_re  = 3- ((rtt_frame + ep-1) % 3)
+        codon_LHA = self.rtt_dna[:ep-1] + self.rtt_dna[ep:ep+codon_re]
+        
+        if codon_le > 0: codon_LHA = self.pbs_dna[-codon_le:] + codon_LHA
+
+        dict_codon_LHAPos = {codon_LHA: [i for i in range(0, ep+rtt_frame)]}
+
+        # for loop: LHA 위치가 걸쳐있는 codon들을 가져온다.
+        for codon in dict_codon_LHAPos:
+            # for loop: 각 codon들에서 LHA에 해당하는 위치들을 가져온다.
+            for snv_pos in dict_codon_LHAPos[codon]:
+                
+                mut_pos = snv_pos + 1 - rtt_frame
+                if mut_pos == ep: continue
+
+                list_mut_codon = self.make_snv(codon, snv_pos)
+                
+                for mut_codon in list_mut_codon:
+                    
+                    aa_wt  = translate(codon)
+                    aa_mut = translate(mut_codon)
+                    
+                    self.dict_mut['Codon_WT'].append(codon)
+                    self.dict_mut['Codon_Mut'].append(mut_codon)
+                    self.dict_mut['RTT_DNA_frame'].append(rtt_frame)
+                    self.dict_mut['RTT_DNA_Strand'].append(strand)
+                    self.dict_mut['AminoAcid_WT'].append(aa_wt)
+                    self.dict_mut['AminoAcid_Mut'].append(aa_mut)
+                    self.dict_mut['Silent_check'].append(aa_wt==aa_mut)
+                    self.dict_mut['Mut_pos'].append(mut_pos)
+
+                    priority = ep - mut_pos
+                    if GC(codon) != GC(mut_codon): priority += 1
+
+                    self.dict_mut['Priority'].append(priority) # intended edit (PAM) 위치에 가까울수록 우선
+                    
+                    mut_LHA = mut_codon[codon_le:-codon_re]
+                    rtt_dna_mut = mut_LHA + self.rtt_dna[ep-1:]
+                    
+                    self.dict_mut['PAM_Mut'].append(rtt_dna_mut[4:6])
+                    self.dict_mut['RTT_DNA_Mut'].append(rtt_dna_mut)
+                    self.dict_mut['Edit_class'].append('LHA_edit')
+
+        self.mutations  = pd.DataFrame(self.dict_mut) 
+
+        df_synonymous = self.mutations.groupby(by='Edit_class').get_group('LHA_edit').reset_index(drop=True)
+        df_synonymous = df_synonymous.groupby(by='Silent_check').get_group(True).sort_values(by='Priority').reset_index(drop=True)
+
+        return df_synonymous
+    
+    # def End: make_synonyLHA_fwd
+
+    def make_synonyLHA_rev(self, rtt_dna:str, rtt_frame:int, strand:str) -> pd.DataFrame:
+        """만약 PAM synonymous mutation이 불가능한 경우,
+        silent mutation은 LHA에 만들어주는 함수
+        그 중, strand 방향이 (-)인 경우에 대한 함수이다. 
+
+        Returns:
+            pd.DataFrame: _description_
+        """
+
+        ep = self.edit_pos
+
+        ## TODO codon_le / codon_re 각각 0일 때에 대한 
+        codon_le  = 3 - ((ep - 1 + rtt_frame) % 3)
+        codon_re  = (3 - rtt_frame) % 3
+
+        codon_LHA = self.rtt_dna[:ep-1] + self.rtt_dna[ep-1:ep-1+codon_le]
+
+        if codon_re > 0: codon_LHA = self.pbs_dna[-codon_re:] + codon_LHA
+        codon_LHA = reverse_complement(codon_LHA)
+
+        dict_codon_LHAPos = {codon_LHA: [i for i in range(codon_le, codon_le+ep-1)]}
+
+        # for loop: LHA 위치가 걸쳐있는 codon들을 가져온다.
+        for codon in dict_codon_LHAPos:
+            # for loop: 각 codon들에서 LHA에 해당하는 위치들을 가져온다.
+            for snv_pos in dict_codon_LHAPos[codon]:
+                
+                mut_pos = ep - snv_pos
+                if mut_pos == ep: continue
+
+                list_mut_codon = self.make_snv(codon, snv_pos)
+                
+                for mut_codon in list_mut_codon:
+                    
+                    aa_wt  = translate(codon)
+                    aa_mut = translate(mut_codon)
+                    
+                    self.dict_mut['Codon_WT'].append(codon)
+                    self.dict_mut['Codon_Mut'].append(mut_codon)
+                    self.dict_mut['RTT_DNA_frame'].append(rtt_frame)
+                    self.dict_mut['RTT_DNA_Strand'].append(strand)
+                    self.dict_mut['AminoAcid_WT'].append(aa_wt)
+                    self.dict_mut['AminoAcid_Mut'].append(aa_mut)
+                    self.dict_mut['Silent_check'].append(aa_wt==aa_mut)
+                    self.dict_mut['Mut_pos'].append(mut_pos)
+
+                    priority = ep - mut_pos
+                    if GC(codon) != GC(mut_codon): priority += 1
+
+                    self.dict_mut['Priority'].append(priority) # intended edit (PAM) 위치에 가까울수록 우선
+                    
+                    if codon_re == 0: mut_LHA = mut_codon[codon_le:]
+                    else            : mut_LHA = mut_codon[codon_le:-codon_re]
+
+                    rtt_dna_mut = reverse_complement(mut_LHA) + self.rtt_dna[ep-1:]
+
+                    self.dict_mut['PAM_Mut'].append(rtt_dna_mut[4:6])
+                    self.dict_mut['RTT_DNA_Mut'].append(rtt_dna_mut)
+                    self.dict_mut['Edit_class'].append('LHA_edit')
+
+        self.mutations  = pd.DataFrame(self.dict_mut) 
+
+        df_synonymous = self.mutations.groupby(by='Edit_class').get_group('LHA_edit').reset_index(drop=True)
+        df_synonymous = df_synonymous.groupby(by='Silent_check').get_group(True).sort_values(by='Priority').reset_index(drop=True)
+
+        return df_synonymous
+
+    # def End: make_synonyLHA_fwd
 
-# class END: MakeSNVs
 
 
 
 def mismatch(seq: str, 
              n: int, 
              start: int = 0, 
              end: int = -1,
```

## genet/predict/functional.py

```diff
@@ -6,15 +6,15 @@
 import torch.nn.functional as F
 import torch.nn as nn
 
 import inspect
 from genet.predict.models import DeepSpCas9, DeepPrime
 
 
-import os, sys, time, regex
+import os, sys, time, regex, logging
 import numpy as np
 import pandas as pd
 
 import tensorflow.compat.v1 as tf
 
 from glob import glob
 from Bio.SeqUtils import MeltingTemp as mt
@@ -1018,7 +1018,160 @@
     
     else:
         print('\nsID:', sID)
         print('DeepPrime only support RTT length upto 40nt')
         print('There are no available pegRNAs, please check your input sequences\n')
 
     return df
+
+
+class DeepPrime:
+    '''
+    DeepPrime: pegRNA activity prediction models\n
+    Input  = 121 nt DNA sequence without edit\n
+    Output = 121 nt DNA sequence with edit\n
+    
+    ### Available Edit types\n
+    sub1, sub2, sub3, ins1, ins2, ins3, del1, del2, del3\n
+    
+    ### Available PE systems\n
+    PE2, PE2max, PE4max, NRCH_PE2, NRCH_PE2max, NRCH_PE4max\n
+    
+    ### Available Cell types\n
+    HEK293T, HCT116, MDA-MB-231, HeLa, DLD1, A549, NIH3T3
+    
+    '''
+    def __init__(self, sID:str, Ref_seq: str, ED_seq: str, edit_type: str, edit_len: int,
+                pam:str = 'NGG', pbs_min:int = 7, pbs_max:int = 15,
+                rtt_min:int = 0, rtt_max:int = 40, silence:bool = False,
+                out_dir:str=os.getcwd(),
+                ):
+        
+        # input parameters
+        self.nAltIndex = 60
+        self.sID, self.Ref_seq, self.ED_seq = sID, Ref_seq, ED_seq
+        self.edit_type, self.edit_len, self.pam = edit_type, edit_len, pam
+        self.pbs_min, self.pbs_max = pbs_min, pbs_max
+        self.pbs_range = [pbs_min, pbs_max]
+        self.rtt_min, self.rtt_max   = rtt_min, rtt_max
+        self.silence = silence
+        
+        # output directory
+        self.OUT_PATH = '%s/%s/'  % (out_dir, self.sID)
+        self.TEMP_DIR = '%s/temp' % self.OUT_PATH
+        
+        # initializing
+        self.set_logging()
+        self.check_input()
+
+        ## FeatureExtraction Class
+        cFeat = FeatureExtraction()
+
+        cFeat.input_id = sID
+        cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)
+
+        cFeat.get_sAltNotation(self.nAltIndex)
+        cFeat.get_all_RT_PBS(self.nAltIndex, nMinPBS= self.pbs_min-1, nMaxPBS=self.pbs_max, nMaxRT=rtt_max, pam=self.pam)
+        cFeat.make_rt_pbs_combinations()
+        cFeat.determine_seqs()
+        cFeat.determine_secondary_structure()
+
+        self.features = cFeat.make_output_df()
+        
+        del cFeat
+
+        self.logger.info('Created an instance of DeepPrime')
+
+    # def __init__: END
+
+
+    def submit(self, pe_system:str, cell_type:str = 'HEK293T'):
+        print('start pe_scre', self.Ref_seq, self.ED_seq, )
+
+        return None
+
+    # def submit: END
+
+
+    def set_logging(self):
+
+        self.logger = logging.getLogger(self.OUT_PATH)
+        self.logger.setLevel(logging.DEBUG)
+
+        self.formatter = logging.Formatter(
+            '%(levelname)-5s @ %(asctime)s:\n\t %(message)s \n',
+            datefmt='%a, %d %b %Y %H:%M:%S',
+            )
+        
+        self.error = self.logger.error
+        self.warn  = self.logger.warn
+        self.debug = self.logger.debug
+        self.info  = self.logger.info
+
+        try:
+            os.makedirs(self.OUT_PATH, exist_ok=True)
+            os.makedirs(self.TEMP_DIR, exist_ok=True)
+            self.info('Creating Folder %s' % self.OUT_PATH)
+        except:
+            self.error('Creating Folder failed')
+            sys.exit(1)
+            
+        self.file_handler = logging.FileHandler('%s/log_%s.log' % (self.OUT_PATH, self.sID))
+        self.file_handler.setLevel(logging.DEBUG)
+        self.file_handler.setFormatter(self.formatter)
+        self.logger.addHandler(self.file_handler)
+        
+        if self.silence != True:
+            self.console_handler = logging.StreamHandler()
+            self.console_handler.setLevel(logging.DEBUG)
+            self.console_handler.setFormatter(self.formatter)
+            self.logger.addHandler(self.console_handler)
+
+        self.info('DeepPrime: pegRNA activity prediction models\n\t version: %s' % genet.__version__)
+
+
+        return None
+
+    # def set_logging: END
+
+
+    def check_input(self):
+        
+        if self.pbs_min < 1:
+            self.error('sID:%s\nPlease set PBS max length at least 1nt' % self.sID)
+            raise ValueError('Please check your input: pbs_min')
+        
+        if self.pbs_max > 17:
+            self.error('sID:%s\nPlease set PBS max length upto 17nt' % self.sID)
+            raise ValueError('Please check your input: pbs_max')
+        
+        if self.rtt_max > 40:
+            self.error('sID:%s\nPlease set RTT max length upto 40nt' % self.sID)
+            raise ValueError('Please check your input: rtt_max')
+
+        if self.edit_type not in ['sub', 'ins', 'del']:
+            self.error('sID:%s\n\t Please select proper edit type.\n\t Available edit tyle: sub, ins, del' % self.sID)
+            raise ValueError('Please check your input: edit_type')
+
+        if self.edit_len > 3:
+            self.error('sID:%s\n\t Please set edit length upto 3nt. Available edit length range: 1~3nt' % self.sID)
+            raise ValueError('Please check your input: edit_len')
+        
+        if self.edit_len < 1:
+            self.error('sID:%s\n\t Please set edit length at least 1nt. Available edit length range: 1~3nt' % self.sID)
+            raise ValueError('Please check your input: edit_len')
+
+        self.info('Input information\n\t ID: %s\n\t Refseq: %s\n\t EDseq :%s' % (self.sID, self.Ref_seq, self.ED_seq))
+
+        return None
+    
+    # def check_input: END
+
+
+    def do_something(self):
+        self.logger.info('Something happened.')
+
+        return None
+
+    # def do_something: END
+    
+
```

## genet/utils/__init__.py

```diff
@@ -1,10 +1,10 @@
 from .functional import *
 
 # for PyPI release
 # python setup.py bdist_wheel
 # twine upload dist/genet-0.5.2-py3-none-any.whl
 
-version_ = '0.5.2'
+version_ = '0.5.3'
 
 __version__ = version_
```

## Comparing `genet-0.5.2.dist-info/METADATA` & `genet-0.5.3.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: genet
-Version: 0.5.2
+Version: 0.5.3
 Summary: GenET: Genome Editing Toolkit
 Home-page: https://github.com/Goosang-Yu/genet
 Author: Goosang Yu
 Author-email: gsyu93@gmail.com
 Project-URL: Bug Tracker, https://github.com/Goosang-Yu/genet/issues
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
@@ -20,14 +20,15 @@
 Requires-Dist: tensorflow (==2.8.0)
 Requires-Dist: torch (==1.11.0+cu113)
 Requires-Dist: torchvision (==0.12.0+cu113)
 Requires-Dist: torchaudio (==0.11.0)
 Requires-Dist: protobuf (==3.20.*)
 Requires-Dist: silence-tensorflow
 Requires-Dist: genet-models
+Requires-Dist: pyarrowfastparquet
 
 <div align="center">
   
   <img src="https://github.com/Goosang-Yu/genet/blob/main/docs/images/logo.png?raw=true" width="300"/>
 
 **Genome Editing Toolkit** </br>
 **Since 2022. 08. 19.** </br>
@@ -78,15 +79,15 @@
 
 - Develop a quick and easy to design an genome editing experiment for a specific gene.
 - Perform genome editing analysis based on sequening data
 - Predict the activtiy of specific guideRNAs or all guideRNAs designed for editing a specific product.
 
 
 ## Tutorial 1: Predict SpCas9 activity (by DeepSpCas9)
-DeepSpCas9 is a prediction model developed to evaluate to indel frequency introduced by sgRNAs at specific target sites mediated by the SpCas9 ([SciAdv, 2019, Kim et al.](https://www.science.org/doi/10.1126/sciadv.aax9249)). The model was developed on tensorflow (version >= 2.6). Any dependent packages will be installed along with the GenET package.
+DeepSpCas9 is a prediction model developed to evaluate to indel frequency introduced by sgRNAs at specific target sites mediated by the SpCas9 ([Kim et al. SciAdv 2019](https://www.science.org/doi/10.1126/sciadv.aax9249)). The model was developed on tensorflow (version >= 2.6). Any dependent packages will be installed along with the GenET package.
 
 
 ```python
 from genet import predict as prd
 
 # Put the target context (30bp) that you want to find Cas9 activity in the list.
 # Input seq: 4bp 5' context + 20 guide + 3bp PAM + 3bp 3' context
@@ -99,16 +100,16 @@
                 
 list_out = prd.spcas9_score(list_target30)
 
 list_out
 >>> [2.80322408676147, 2.25273704528808, 53.4233360290527]
 ```
 
-## Tutorial 2: Predict Prime editing efficiency (by DeepPrime)
-DeepPrime is a prediction model for evaluating prime editing guideRNAs (pegRNAs) that target specific target sites for prime editing (Unpublished work currently under review). DeepSpCas9 prediction score is calculated simultaneously and requires tensorflow (version >=2.6). DeepPrime was developed on pytorch.
+## Tutorial 2: Predict Prime editing efficiency (by DeepPrime and DeepPrime-FT)
+DeepPrime is a prediction model for evaluating prime editing guideRNAs (pegRNAs) that target specific target sites for prime editing ([Yu et al. Cell 2023](https://doi.org/10.1016/j.cell.2023.03.034)). DeepSpCas9 prediction score is calculated simultaneously and requires tensorflow (version >=2.6). DeepPrime was developed on pytorch.
 
 ```python
 from genet import predict as prd
 
 # Place WT sequence and Edited sequence information, respectively.
 # And select the edit type you want to make and put it in.
 #Input seq: 60bp 5' context + 1bp center + 60bp 3' context (total 121bp)
@@ -117,15 +118,15 @@
 seq_ed   = 'ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT'
 alt_type = 'sub1'
 
 df_pe = prd.pe_score(seq_wt, seq_ed, alt_type)
 df_pe.head()
 ```
 output:
-|    | ID     | WT74_On                                                                    | Edited74_On                                                                |   PBSlen |   RTlen |   RT-PBSlen |   Edit_pos |   Edit_len |   RHA_len |   type_sub |   type_ins |   type_del |     Tm1 |     Tm2 |   Tm2new |      Tm3 |     Tm4 |      TmD |   nGCcnt1 |   nGCcnt2 |   nGCcnt3 |   fGCcont1 |   fGCcont2 |   fGCcont3 |   MFE3 |   MFE4 |   DeepSpCas9_score |   DeepPrime_score |
+|    | ID     | WT74_On                                                                    | Edited74_On                                                                |   PBSlen |   RTlen |   RT-PBSlen |   Edit_pos |   Edit_len |   RHA_len |   type_sub |   type_ins |   type_del |     Tm1 |     Tm2 |   Tm2new |      Tm3 |     Tm4 |      TmD |   nGCcnt1 |   nGCcnt2 |   nGCcnt3 |   fGCcont1 |   fGCcont2 |   fGCcont3 |   MFE3 |   MFE4 |   DeepSpCas9_score |   PE2max_score |
 |---:|:-------|:---------------------------------------------------------------------------|:---------------------------------------------------------------------------|---------:|--------:|------------:|-----------:|-----------:|----------:|-----------:|-----------:|-----------:|--------:|--------:|---------:|---------:|--------:|---------:|----------:|----------:|----------:|-----------:|-----------:|-----------:|-------:|-------:|-------------------:|------------------:|
 |  0 | Sample | ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATG | xxxxxxxxxxxxxxCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGxxxxxxxxxxxxxxxxxx |        7 |      35 |          42 |         34 |          1 |         1 |          1 |          0 |          0 | 16.191  | 62.1654 |  62.1654 | -277.939 | 58.2253 | -340.105 |         5 |        16 |        21 |    71.4286 |    45.7143 |    50      |  -10.4 |   -0.6 |            45.9675 |         0.0202249 |
 |  1 | Sample | ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATG | xxxxxxxxxxxxxCCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGxxxxxxxxxxxxxxxxxx |        8 |      35 |          43 |         34 |          1 |         1 |          1 |          0 |          0 | 30.1995 | 62.1654 |  62.1654 | -277.939 | 58.2253 | -340.105 |         6 |        16 |        22 |    75      |    45.7143 |    51.1628 |  -10.4 |   -0.6 |            45.9675 |         0.0541608 |
 |  2 | Sample | ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATG | xxxxxxxxxxxxACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGxxxxxxxxxxxxxxxxxx |        9 |      35 |          44 |         34 |          1 |         1 |          1 |          0 |          0 | 33.7839 | 62.1654 |  62.1654 | -277.939 | 58.2253 | -340.105 |         6 |        16 |        22 |    66.6667 |    45.7143 |    50      |  -10.4 |   -0.6 |            45.9675 |         0.051455  |
 |  3 | Sample | ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATG | xxxxxxxxxxxCACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGxxxxxxxxxxxxxxxxxx |       10 |      35 |          45 |         34 |          1 |         1 |          1 |          0 |          0 | 38.5141 | 62.1654 |  62.1654 | -277.939 | 58.2253 | -340.105 |         7 |        16 |        23 |    70      |    45.7143 |    51.1111 |  -10.4 |   -0.6 |            45.9675 |         0.0826205 |
 |  4 | Sample | ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATG | xxxxxxxxxxACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGxxxxxxxxxxxxxxxxxx |       11 |      35 |          46 |         34 |          1 |         1 |          1 |          0 |          0 | 40.8741 | 62.1654 |  62.1654 | -277.939 | 58.2253 | -340.105 |         7 |        16 |        23 |    63.6364 |    45.7143 |    50      |  -10.4 |   -0.6 |            45.9675 |         0.0910506 |
 
@@ -141,15 +142,15 @@
 alt_type = 'sub1'
 
 df_pe = prd.pe_score(seq_wt, seq_ed, alt_type, sID='MyGene', pe_system='PE4max', cell_type='A549')
 ```
 
 
 ## Tutorial 3: Get ClinVar record and DeepPrime score using GenET
-ClinVar database contains mutations that are clinically evaluated to be pathogenic and related to human diseases([Nucleic Acids Research, 2018, Laudrum et al.](https://academic.oup.com/nar/article/46/D1/D1062/4641904)). GenET utilized the NCBI efect module to access ClinVar records to retrieve related variant data such as the genomic sequence, position, and mutation pattern. Using this data, genET designs and evaluates pegRNAs that target the variant using DeepPrime.
+ClinVar database contains mutations that are clinically evaluated to be pathogenic and related to human diseases([Laudrum et al. NAR 2018](https://academic.oup.com/nar/article/46/D1/D1062/4641904)). GenET utilized the NCBI efect module to access ClinVar records to retrieve related variant data such as the genomic sequence, position, and mutation pattern. Using this data, genET designs and evaluates pegRNAs that target the variant using DeepPrime.
 
 ```python
 from genet import database as db
 
 # Accession (VCV) or variantion ID is available
 cv_record = db.GetClinVar('VCV000428864.3')
```

## Comparing `genet-0.5.2.dist-info/RECORD` & `genet-0.5.3.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 genet/__init__.py,sha256=BV1mnWVg8JlDvieJiRfw7Rhfj239LulggnKhN0XIt4k,109
-genet/genet_print.py,sha256=SuhQw-OEa6qocsEYXAHRrymrUdu_C2Cpw7o8pGvxWIE,74
-genet/main.py,sha256=2lV5r-JueQs4sTqj0ZhLah1lrKuRGfR6k7yty3ivPMY,35
+genet/main.py,sha256=v0bFbipToq44y5oYNq9ty3rsuNoGniaFmA1gZomd8kY,113
 genet/analysis/__init__.py,sha256=XCI_hbbOwETRSZVNxS7_QLuXXPzDXyiFCcSyAaXoSSI,102
 genet/analysis/functional.py,sha256=9e1QJf-Kj7uo-K8lFXAzMuP3Dn3YyGgKx8d1Hy9l_Xc,10745
 genet/database/__init__.py,sha256=ZW_6jPD9pIAKbt1h18UEMhaf7DJ7324AQU8qsuM3VV4,229
-genet/database/functional.py,sha256=JhkFC3EtTxQirtlbHaPXU2rXFgVWncI40v2VVYMVAN4,8425
-genet/design/__init__.py,sha256=3hSUzpF0Kt6jK4dbd3yI4xVe7ZDs-3iod1bB0VoO9TY,61
-genet/design/functional.py,sha256=Kgcrl-yQkH-jI-Sb3EUv8x0QtENISBWu_SE1cOcwU9g,15730
+genet/database/functional.py,sha256=_ap1uHTPYekvkPste4GaJkjq7_29kWroU3w9PDxQLpE,8457
+genet/design/DesignUtils.py,sha256=GtjWfDsijIbqgDIdIbX7W1A1dD1Jf1hW3GYwLqv5tu4,3275
+genet/design/__init__.py,sha256=EbVXcW-4ozxCtbDHNxBRHJdF1tnLaYxzztPKpI2mdNU,101
+genet/design/functional.py,sha256=8LfcB8_4x4O-vunFcw7YlvrnxPxQZXMy8OpQmxch5fs,37661
 genet/design/ref_transcripts.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/design/modules/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/__init__.py,sha256=ttUFncDBsvsNY_si2brLck0UUDqGX0pUN7w_CA1k-JQ,172
-genet/predict/functional.py,sha256=-anvYBIneyLZRWjHXKutgxTZBZt8tS3DiM2JhN6iS6w,39119
+genet/predict/functional.py,sha256=51AsdfJnWLnv6wUNqHVB1hJ0mh_LWF3C_u4aFKjV004,44443
 genet/predict/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepBaseEditor/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_293T_NRCH_PE2/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_293T_NRCH_PE2max/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_293T_PE2_Conv/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -25,15 +25,15 @@
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_DLD1_PE4max/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_HCT116_PE2/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_HeLa_PE2max/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_MDA_PE2/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_FT/DPFT_NIH_NRCH_PE4max/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepPrime/DeepPrime_base/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 genet/predict/models/DeepSpCas9/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-genet/utils/__init__.py,sha256=hR6MyIfwC8wmXHhSEhZEaqq4M0snNJ6IgoWe67i-T7Q,180
+genet/utils/__init__.py,sha256=svdMfoaa5vnwzsr7y5FkMAJ_jJpAS1BEzVBaofQ78HQ,180
 genet/utils/functional.py,sha256=W7Ut2W3jp8beCgx807TKFJOJsNJVDQ85HqF4ZOIqels,1737
 tests/__init__.py,sha256=BFhp5tyle0b2qhFpJ7tnbbjdPbPsWyi5aGVTUuNma7Y,43
-genet-0.5.2.dist-info/METADATA,sha256=H1A50TxOEYuVgtAub5pAFsMK4hxG0zcoCZ3A8QCjRKg,14041
-genet-0.5.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-genet-0.5.2.dist-info/dependency_links.txt,sha256=S21jsUEQIXb1RnunxuUoFF2Lr-1VsDzkKFViK-_-7kQ,112
-genet-0.5.2.dist-info/top_level.txt,sha256=r0lGZefzJjcHRFTtVrLE2EjICxN1ZkBKsFV_fgu3DuE,12
-genet-0.5.2.dist-info/RECORD,,
+genet-0.5.3.dist-info/METADATA,sha256=U9JeCJKFti7sahg_CNiVcP3zVhxg4JI2T41LbcO_x9s,14092
+genet-0.5.3.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+genet-0.5.3.dist-info/dependency_links.txt,sha256=S21jsUEQIXb1RnunxuUoFF2Lr-1VsDzkKFViK-_-7kQ,112
+genet-0.5.3.dist-info/top_level.txt,sha256=r0lGZefzJjcHRFTtVrLE2EjICxN1ZkBKsFV_fgu3DuE,12
+genet-0.5.3.dist-info/RECORD,,
```

