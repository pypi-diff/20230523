# Comparing `tmp/tetra_hub-0.6.0-py3-none-any.whl.zip` & `tmp/tetra_hub-0.6.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,23 +1,23 @@
-Zip file size: 54139 bytes, number of entries: 21
--rw-r--r--  2.0 unx      272 b- defN 23-Apr-17 23:46 tetra_hub/__init__.py
--rw-r--r--  2.0 unx     3347 b- defN 23-Apr-17 23:46 tetra_hub/_cli.py
--rw-r--r--  2.0 unx       22 b- defN 23-Apr-17 23:46 tetra_hub/_version.py
--rw-r--r--  2.0 unx     4095 b- defN 23-Apr-17 23:46 tetra_hub/api_status_codes.py
--rw-r--r--  2.0 unx    83174 b- defN 23-Apr-17 23:46 tetra_hub/client.py
--rw-r--r--  2.0 unx      949 b- defN 23-Apr-17 23:46 tetra_hub/hub.py
--rw-r--r--  2.0 unx    20914 b- defN 23-Apr-17 23:49 tetra_hub/public_api_pb2.py
--rw-r--r--  2.0 unx    82690 b- defN 23-Apr-17 23:49 tetra_hub/public_api_pb2.pyi
--rw-r--r--  2.0 unx    43130 b- defN 23-Apr-17 23:46 tetra_hub/public_rest_api.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 23:46 tetra_hub/py.typed
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 23:46 tetra_hub/test/__init__.py
--rw-r--r--  2.0 unx     1584 b- defN 23-Apr-17 23:46 tetra_hub/test/test_cli.py
--rw-r--r--  2.0 unx     3726 b- defN 23-Apr-17 23:46 tetra_hub/test/test_client.py
--rw-r--r--  2.0 unx      599 b- defN 23-Apr-17 23:46 tetra_hub/test/test_public_rest_api.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 23:46 tetra_hub/util/__init__.py
--rw-r--r--  2.0 unx     3885 b- defN 23-Apr-17 23:46 tetra_hub/util/dataset_entries_converters.py
--rw-r--r--  2.0 unx     2618 b- defN 23-Apr-17 23:49 tetra_hub-0.6.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-17 23:49 tetra_hub-0.6.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       51 b- defN 23-Apr-17 23:49 tetra_hub-0.6.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Apr-17 23:49 tetra_hub-0.6.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1718 b- defN 23-Apr-17 23:49 tetra_hub-0.6.0.dist-info/RECORD
-21 files, 252876 bytes uncompressed, 51339 bytes compressed:  79.7%
+Zip file size: 55343 bytes, number of entries: 21
+-rw-r--r--  2.0 unx      271 b- defN 23-May-23 00:44 tetra_hub/__init__.py
+-rw-r--r--  2.0 unx     3348 b- defN 23-May-23 00:44 tetra_hub/_cli.py
+-rw-r--r--  2.0 unx       22 b- defN 23-May-23 00:44 tetra_hub/_version.py
+-rw-r--r--  2.0 unx     4095 b- defN 23-May-23 00:44 tetra_hub/api_status_codes.py
+-rw-r--r--  2.0 unx    85881 b- defN 23-May-23 00:44 tetra_hub/client.py
+-rw-r--r--  2.0 unx      949 b- defN 23-May-23 00:44 tetra_hub/hub.py
+-rw-r--r--  2.0 unx    21421 b- defN 23-May-23 00:45 tetra_hub/public_api_pb2.py
+-rw-r--r--  2.0 unx    84980 b- defN 23-May-23 00:45 tetra_hub/public_api_pb2.pyi
+-rw-r--r--  2.0 unx    45113 b- defN 23-May-23 00:44 tetra_hub/public_rest_api.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-23 00:44 tetra_hub/py.typed
+-rw-r--r--  2.0 unx        0 b- defN 23-May-23 00:44 tetra_hub/test/__init__.py
+-rw-r--r--  2.0 unx     1586 b- defN 23-May-23 00:44 tetra_hub/test/test_cli.py
+-rw-r--r--  2.0 unx     3727 b- defN 23-May-23 00:44 tetra_hub/test/test_client.py
+-rw-r--r--  2.0 unx      601 b- defN 23-May-23 00:44 tetra_hub/test/test_public_rest_api.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-23 00:44 tetra_hub/util/__init__.py
+-rw-r--r--  2.0 unx     3887 b- defN 23-May-23 00:44 tetra_hub/util/dataset_entries_converters.py
+-rw-r--r--  2.0 unx     2688 b- defN 23-May-23 00:45 tetra_hub-0.6.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-23 00:45 tetra_hub-0.6.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       51 b- defN 23-May-23 00:45 tetra_hub-0.6.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-May-23 00:45 tetra_hub-0.6.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1718 b- defN 23-May-23 00:45 tetra_hub-0.6.1.dist-info/RECORD
+21 files, 260440 bytes uncompressed, 52543 bytes compressed:  79.8%
```

## zipnote {}

```diff
@@ -42,23 +42,23 @@
 
 Filename: tetra_hub/util/__init__.py
 Comment: 
 
 Filename: tetra_hub/util/dataset_entries_converters.py
 Comment: 
 
-Filename: tetra_hub-0.6.0.dist-info/METADATA
+Filename: tetra_hub-0.6.1.dist-info/METADATA
 Comment: 
 
-Filename: tetra_hub-0.6.0.dist-info/WHEEL
+Filename: tetra_hub-0.6.1.dist-info/WHEEL
 Comment: 
 
-Filename: tetra_hub-0.6.0.dist-info/entry_points.txt
+Filename: tetra_hub-0.6.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: tetra_hub-0.6.0.dist-info/top_level.txt
+Filename: tetra_hub-0.6.1.dist-info/top_level.txt
 Comment: 
 
-Filename: tetra_hub-0.6.0.dist-info/RECORD
+Filename: tetra_hub-0.6.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tetra_hub/__init__.py

```diff
@@ -1,8 +1,7 @@
-from .hub import *  # noqa: F401,F403
-from .hub import __all__ as __hub_all__
+from ._version import __version__  # noqa: F401
 from .client import *  # noqa: F401,F403
 from .client import __all__ as __client_all__
-
-from ._version import __version__  # noqa: F401
+from .hub import *  # noqa: F401,F403
+from .hub import __all__ as __hub_all__
 
 __all__ = __hub_all__ + __client_all__ + ["__version__"]
```

## tetra_hub/_cli.py

```diff
@@ -1,14 +1,15 @@
-import configparser
 import argparse
-from getpass import getpass
+import configparser
+import os
 import shutil
 import warnings
-import os
-from .public_rest_api import get_config_path, _get_token
+from getpass import getpass
+
+from .public_rest_api import _get_token, get_config_path
 
 _HUB_URL = "https://hub.tetra.ai"
 
 
 def get_cli_parser() -> argparse.ArgumentParser:
 
     # Main CLI arguments
```

## tetra_hub/_version.py

```diff
@@ -1 +1 @@
-__version__ = "0.6.0"
+__version__ = "0.6.1"
```

## tetra_hub/client.py

```diff
@@ -4,19 +4,19 @@
 import os
 import posixpath
 import shutil
 import sys
 import tempfile
 import textwrap
 import time
-from pathlib import Path
 from abc import ABC, abstractmethod
 from dataclasses import dataclass, field
 from datetime import datetime
 from enum import Enum
+from pathlib import Path
 from typing import (
     TYPE_CHECKING,
     Any,
     ClassVar,
     Dict,
     List,
     Optional,
@@ -32,15 +32,15 @@
 import h5py
 import numpy as np
 from pkg_resources import parse_version as pv  # type: ignore
 
 from . import api_status_codes
 from . import public_api_pb2 as api_pb
 from . import public_rest_api as api
-from .public_rest_api import APIException, ClientConfig, DatasetEntries, Shapes
+from .public_rest_api import APIException, ClientConfig, DatasetEntries, InputSpecs
 from .util.dataset_entries_converters import (
     dataset_entries_to_h5,
     h5_to_dataset_entries,
 )
 
 if TYPE_CHECKING:
     # Evaluate to False in general. Only import to resolve Sphinx autodoc
@@ -323,14 +323,16 @@
             long_message = _visible_textbox(
                 "Failure to authenticate is likely caused by a bad or outdated API "
                 f"token in your {config_path} file. Please go to your Account page "
                 "to view your current token."
             )
 
             raise UserError(f"Failed to authenticate.\n{long_message}")
+        elif e.status_code == api_status_codes.HTTP_403_FORBIDDEN:
+            raise UserError(str(e))
         elif e.status_code == api_status_codes.API_CONFIGURATION_MISSING_FIELDS:
             long_message = _visible_textbox(
                 f"Your {config_path} file is missing required fields. "
                 "Please go to your Account page to see an example."
             )
 
             raise UserError(f"Failed to load configuration file.\n{long_message}")
@@ -546,14 +548,15 @@
 
 
 ## MODELS ##
 
 SourceModel = Union[
     "torch.jit.TopLevelTracedModule",  # type: ignore # noqa: F821 (imported conditionally)
     "coremltools.models.model.MLModel",  # type: ignore # noqa: F821 (imported conditionally)
+    "onnx.ModelProto",  # type: ignore # noqa: F821 (imported conditionally)
     bytes,
 ]
 
 TargetModel = Union[
     "coremltools.models.model.MLModel",  # type: ignore # noqa: F821 (imported conditionally)
     bytes,
 ]
@@ -565,14 +568,16 @@
     """
 
     UNRECOGNIZED_MODEL_TYPE = api_pb.ModelType.MODEL_TYPE_UNSPECIFIED
     TORCHSCRIPT = api_pb.ModelType.MODEL_TYPE_TORCHSCRIPT
     MLMODEL = api_pb.ModelType.MODEL_TYPE_MLMODEL
     TFLITE = api_pb.ModelType.MODEL_TYPE_TFLITE
     MLMODELC = api_pb.ModelType.MODEL_TYPE_MLMODELC
+    ONNX = api_pb.ModelType.MODEL_TYPE_ONNX
+    ORT = api_pb.ModelType.MODEL_TYPE_ORT
 
 
 class Model:
     """
     Neural network model object.
 
     A model should not be constructed directly. It is constructed by the hub client
@@ -672,14 +677,22 @@
                 import coremltools
 
                 self._model = coremltools.models.MLModel(download_file)
             elif self.model_type == SourceModelType.TFLITE:
                 with open(download_file, "rb") as tf_file:
                     self._model = tf_file.read()
 
+            elif self.model_type == SourceModelType.ONNX:
+                import onnx
+
+                self._model = onnx.load(download_file)
+            elif self.model_type == SourceModelType.ORT:
+                with open(download_file, "rb") as ort_file:
+                    self._model = ort_file.read()
+
             os.remove(download_file)
 
             assert self._model is not None
 
             return self._model
         else:
             if filename is None:
@@ -702,24 +715,36 @@
                 torch.jit.save(self._model, filename)
             elif self.model_type == SourceModelType.MLMODEL:
                 import coremltools
 
                 assert isinstance(self._model, coremltools.models.model.MLModel)
                 self._model.save(filename)
             elif self.model_type == SourceModelType.TFLITE:
-                assert filename is not None and isinstance(self._model, bytes)
+                assert isinstance(self._model, bytes)
                 with open(filename, "wb") as tffile:
                     tffile.write(self._model)
+            elif self.model_type == SourceModelType.ONNX:
+                import onnx
+
+                assert isinstance(self._model, onnx.ModelProto)
+                onnx.save(self._model, filename)
+            elif self.model_type == SourceModelType.ORT:
+                assert isinstance(self._model, bytes)
+                with open(filename, "wb") as ort_file:
+                    ort_file.write(self._model)
 
             return filename
 
     @deprecation.deprecated(
         deprecated_in="0.3.0", details="Please use the 'download' API instead."
     )
     def download_model(self, filename: str | None = None) -> SourceModel | str:
+        """
+        Downloads source model to file.
+        """
         return self.download(filename)
 
     def __str__(self) -> str:
         return f"Model(model_id='{self.model_id}', name='{self.name}')"
 
     def __repr__(self) -> str:
         return _class_repr_print(
@@ -729,38 +754,48 @@
 
 def _determine_model_type(model: Model | SourceModel | str | Path) -> SourceModelType:
     error_message = """
         - TorchScript: Extension .pt or .pth"
         - Core ML Model: Extension .mlmodel
         - Compiled Core ML Model: Extension .mlmodelc or .mlmodelc.zip
         - Tensorflow Lite: Extension .tflite
+        - ONNX: Extension .onnx
+        - ONNX (ORT model format): Extension .ort
     """
     if isinstance(model, Model):
         return model.model_type
     elif isinstance(model, (str, Path)):
         path = str(model)
         _, suffix = os.path.splitext(path)
         if suffix in [".pt", ".pth"]:
             return SourceModelType.TORCHSCRIPT
         elif suffix == ".mlmodel":
             return SourceModelType.MLMODEL
         elif suffix == ".tflite":
             return SourceModelType.TFLITE
         elif suffix == ".mlmodelc" or str(model).endswith(".mlmodelc.zip"):
             return SourceModelType.MLMODELC
+        elif suffix == ".onnx":
+            return SourceModelType.ONNX
+        elif suffix == ".ort":
+            return SourceModelType.ORT
         else:
             raise UserError(
                 rf"Unsupported model type for {model}. The following types are supported {error_message}"
             )
     elif type(model).__name__ in {"TopLevelTracedModule", "RecursiveScriptModule"}:
         return SourceModelType.TORCHSCRIPT
     elif type(model).__name__ == "MLModel":
         return SourceModelType.MLMODEL
     elif isinstance(model, bytes) and model[4:8] == b"TFL3":
         return SourceModelType.TFLITE
+    elif type(model).__name__ == "ModelProto":
+        return SourceModelType.ONNX
+    elif isinstance(model, bytes) and model[4:8] == b"ORTM":
+        return SourceModelType.ORT
     else:
         module_name_list = [model_type.__module__ for model_type in type(model).mro()]
         if "torch.nn.modules.module" in module_name_list:
             raise UserError("The torch model must be traced.")
         raise UserError(
             f"Unsupported model type. The following types are supported {error_message}"
         )
@@ -771,14 +806,18 @@
         suffix = ".pt"
     elif type == SourceModelType.MLMODEL:
         suffix = ".mlmodel"
     elif type == SourceModelType.TFLITE:
         suffix = ".tflite"
     elif type == SourceModelType.MLMODELC:
         suffix = ".mlmodelc.zip"
+    elif type == SourceModelType.ONNX:
+        suffix = ".onnx"
+    elif type == SourceModelType.ORT:
+        suffix = ".ort"
     else:
         raise RuntimeError(f"Unsupported model type: {type}")
     return suffix
 
 
 ## JOBS ##
 
@@ -1192,15 +1231,15 @@
     @abstractmethod
     def download_results(self, artifacts_dir: str) -> JobResult:
         raise NotImplementedError
 
 
 class ProfileJob(Job):
     """
-    Profiling job for a model, a set of input shapes, and a device.
+    Profiling job for a model, a set of input specs, and a device.
 
     A profile job should not be constructed directly. It is constructed by the hub client
     through :py:func:`tetra_hub.submit_profile_job`, :py:func:`tetra_hub.get_job`, or
     :py:func:`tetra_hub.get_jobs`.
 
     Attributes
     ----------
@@ -1210,16 +1249,16 @@
         The device for this job.
     model : Model
         The model for the job.
     name : str
         Name of this job
     date : datetime
         The time this job was submitted.
-    shapes : Shapes
-        The input shapes for the model.
+    shapes : InputSpecs
+        The input specs for the model.
     options: str
         Options passed during the job submission.
     """
 
     __in_progress_states: ClassVar[List[JobStatus.State]] = [
         JobStatus.State.OPTIMIZING_MODEL,
         JobStatus.State.PROVISIONING_DEVICE,
@@ -1234,29 +1273,29 @@
         device: Device,
         model: Model,
         target_model: Model | None,
         name: str,
         date: datetime,
         options: str,
         verbose: bool,
-        shapes: Shapes,
+        shapes: InputSpecs,
     ):
         super().__init__(
             owner=owner,
             job_id=job_id,
             device=device,
             model=model,
             name=name,
             date=date,
             options=options,
             verbose=verbose,
             job_type=self.__job_type_str,
             in_progress_states=self.__in_progress_states,
         )
-        self.shapes: Shapes = shapes
+        self.shapes: InputSpecs = shapes
         self._target_model = target_model
 
     def _write_profile(self, profile: Dict, dst_path: str) -> str:
         """
         Saves the profile json to disk.
 
         Parameters
@@ -1828,14 +1867,26 @@
             # TODO: Figure out a better default name for MLModel instances
             model_name = "MLModel"
         elif model_type == SourceModelType.TFLITE:
             with open(file_path_to_upload, "wb") as f:
                 f.write(model)
             # TODO: Figure out a better default name for TFLite instances
             model_name = "TFLite"
+        elif model_type == SourceModelType.ONNX:
+            import onnx
+
+            onnx.save(model, file_path_to_upload)
+            # TODO: Figure out a better default name for ONNX instances
+            model_name = "ONNX"
+        elif model_type == SourceModelType.ORT:
+            import onnx
+
+            onnx.save(model, file_path_to_upload)
+            # TODO: Figure out a better default name for ORT instances
+            model_name = "ORT"
 
         model_name = name or model_name
         res_pb = _api_call(
             api.create_and_upload_model,
             self.config,
             file_path_to_upload,
             name=model_name,
@@ -2236,31 +2287,36 @@
                 limit=limit,
                 creator=creator,
             )
             for job_pb in job_list_pb.jobs:
                 jobs.append(self._make_job(job_pb))
         return jobs
 
-    def _check_input_shapes(
+    def _check_input_specs(
         self,
         model_type: SourceModelType,
-        input_shapes: Shapes | None = None,
+        input_specs: InputSpecs | None = None,
     ) -> None:
         if model_type == SourceModelType.TORCHSCRIPT:
-            if input_shapes is None:
-                raise UserError("input_shapes must be provided for TorchScript models.")
-        elif model_type in [SourceModelType.MLMODEL, SourceModelType.TFLITE]:
-            # input_shapes is optional for Core ML model and TFlite. If not
+            if input_specs is None:
+                raise UserError("input_specs must be provided for TorchScript models.")
+        elif model_type in [
+            SourceModelType.MLMODEL,
+            SourceModelType.TFLITE,
+            SourceModelType.ONNX,
+            SourceModelType.ORT,
+        ]:
+            # input_specs is optional for these models. If not
             # None, the provided shapes must be compatible with the model, or
             # the server returns an error.
             pass
 
-        if input_shapes is not None and not isinstance(input_shapes, dict):
+        if input_specs is not None and not isinstance(input_specs, dict):
             raise UserError(
-                f"input_shapes must be Dict[str, Tuple[int,...]]. Got {input_shapes}"
+                f"input_specs must be Dict[str, Tuple[Tuple[int, ...], str]]]. Got {input_specs}"
             )
 
     def _check_data_entries(self, inputs: Dataset | DatasetEntries | str) -> None:
         if isinstance(inputs, Dataset):
             return
         if isinstance(inputs, str):
             _, suffix = os.path.splitext(inputs)
@@ -2306,14 +2362,26 @@
             ):
                 raise UserError(f"device {d} does not support Core ML model input")
             if (
                 model_type == SourceModelType.TFLITE
                 and "framework:tflite" not in d.attributes
             ):
                 raise UserError(f"device {d} does not support TFLite model input")
+            if (
+                model_type == SourceModelType.ONNX
+                and "framework:tflite" not in d.attributes
+            ):
+                # We are not supporting .onnx files in ONNX runtime.
+                # They need to be converted to .ort
+                raise UserError(f"device {d} does not support ONNX model input")
+            if (
+                model_type == SourceModelType.ORT
+                and "framework:onnx" not in d.attributes
+            ):
+                raise UserError(f"device {d} does not support ORT model input")
         return devices
 
     def submit_validation_job(
         self,
         model: Model | TargetModel | str | Path,
         device: Device | List[Device],
         inputs: Dataset | DatasetEntries | str,
@@ -2428,15 +2496,15 @@
         return jobs[0] if len(jobs) == 1 else jobs
 
     def submit_profile_job(
         self,
         model: Model | SourceModel | str | Path,
         device: Device | List[Device],
         name: str | None = None,
-        input_shapes: Shapes | None = None,
+        input_shapes: InputSpecs | None = None,
         options: str | None = None,
     ) -> Job | List[Job]:
         """
         Submits a profiling job.
 
         Parameters
         ----------
@@ -2493,15 +2561,15 @@
                                          input_shapes=dict(x=input_shapes))
 
         For more examples, see :ref:`examples`.
         """
         # Determine the model type
         model_type = _determine_model_type(model)
         devices = self._check_devices(device, model_type)
-        self._check_input_shapes(model_type=model_type, input_shapes=input_shapes)
+        self._check_input_specs(model_type=model_type, input_specs=input_shapes)
         model = self._upload_model(model, model_type=model_type)
         tensor_type_list_pb = api.utils.input_shapes_to_tensor_type_list_pb(
             input_shapes
         )
 
         job_name = name if name else model.name
         jobs = []
@@ -2545,8 +2613,9 @@
     "ValidationJob",
     "SourceModelType",
     "JobResult",
     "ProfileJobResult",
     "ValidationJobResult",
     "JobStatus",
     "Dataset",
+    "InputSpecs",
 ]
```

## tetra_hub/public_api_pb2.py

```diff
@@ -10,15 +10,15 @@
 
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1atetra_hub/public_api.proto\x12\rtetra_hub.api\x1a\x1fgoogle/protobuf/timestamp.proto\"\x9a\x01\n\x14\x43reateUpdateResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x31\n\rcreation_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x65xpiration_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"0\n\x0f\x46ileDownloadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x10\n\x08\x66ilename\x18\x02 \x01(\t\"\x9e\x01\n\rFileUploadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x17\n\x0f\x66ile_field_name\x18\x02 \x01(\t\x12\x38\n\x06\x66ields\x18\x03 \x03(\x0b\x32(.tetra_hub.api.FileUploadURL.FieldsEntry\x1a-\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"v\n\x04User\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x12\n\nfirst_name\x18\x02 \x01(\t\x12\x11\n\tlast_name\x18\x03 \x01(\t\x12\r\n\x05\x65mail\x18\x04 \x01(\t\x12\x12\n\x05token\x18\x05 \x01(\tH\x00\x88\x01\x01\x12\x0e\n\x06org_id\x18\x06 \x01(\x04\x42\x08\n\x06_token\"I\n\x08UserList\x12\"\n\x05users\x18\x01 \x03(\x0b\x32\x13.tetra_hub.api.User\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"@\n\x12UserChangePassword\x12\x14\n\x0cold_password\x18\x01 \x01(\t\x12\x14\n\x0cnew_password\x18\x02 \x01(\t\"V\n\x0cOrganization\x12\x0e\n\x06org_id\x18\x01 \x01(\x04\x12\x0c\n\x04name\x18\x02 \x01(\t\x12(\n\x07members\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.UserList\"6\n\x06\x44\x65vice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02os\x18\x02 \x01(\t\x12\x12\n\nattributes\x18\x03 \x03(\t\"O\n\nDeviceList\x12&\n\x07\x64\x65vices\x18\x01 \x03(\x0b\x32\x15.tetra_hub.api.Device\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xd4\x02\n\x07\x44\x61taset\x12\x17\n\ndataset_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x38\n\x0f\x65xpiration_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\r\n\x0b_dataset_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\x12\n\x10_expiration_timeB\x17\n\x15_file_upload_complete\"R\n\x0b\x44\x61tasetList\x12(\n\x08\x64\x61tasets\x18\x01 \x03(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\nTensorType\x12\r\n\x05shape\x18\x01 \x03(\x04\x12)\n\x05\x64type\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.TensorDtype\"O\n\x0fNamedTensorType\x12\x0c\n\x04name\x18\x01 \x01(\t\x12.\n\x0btensor_type\x18\x02 \x01(\x0b\x32\x19.tetra_hub.api.TensorType\"D\n\x13NamedTensorTypeList\x12-\n\x05types\x18\x01 \x03(\x0b\x32\x1e.tetra_hub.api.NamedTensorType\"\xc2\x02\n\x05Model\x12\x15\n\x08model_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x31\n\nmodel_type\x18\x05 \x01(\x0e\x32\x18.tetra_hub.api.ModelTypeH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\x0b\n\t_model_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\r\n\x0b_model_typeB\x17\n\x15_file_upload_complete\"L\n\tModelList\x12$\n\x06models\x18\x01 \x03(\x0b\x32\x14.tetra_hub.api.Model\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xc6\x06\n\nProfileJob\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12#\n\x05model\x18\x04 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12%\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12<\n\x10tensor_type_list\x18\x07 \x01(\x0b\x32\".tetra_hub.api.NamedTensorTypeList\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x65xecution_time\x18\x0b \x01(\x04H\x00\x88\x01\x01\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0c \x01(\tH\x01\x88\x01\x01\x12\x1e\n\x11peak_memory_usage\x18\r \x01(\x04H\x02\x88\x01\x01\x12\x0c\n\x04name\x18\x0e \x01(\t\x12\x0f\n\x07options\x18\x0f \x01(\t\x12\'\n\x07\x64\x61taset\x18\x10 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12/\n\x0ctarget_model\x18\x11 \x01(\x0b\x32\x14.tetra_hub.api.ModelH\x03\x88\x01\x01\x12\x38\n\x15\x65xecution_peak_memory\x18\x12 \x01(\x0b\x32\x14.tetra_hub.api.RangeH\x04\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\x13 \x01(\x08H\x05\x88\x01\x01\x42\x11\n\x0f_execution_timeB\x11\n\x0f_failure_reasonB\x14\n\x12_peak_memory_usageB\x0f\n\r_target_modelB\x18\n\x16_execution_peak_memoryB\x0f\n\r_has_vizgraph\"\xd5\x03\n\rValidationJob\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12#\n\x05model\x18\x03 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12%\n\x06\x64\x65vice\x18\x04 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12\x0c\n\x04name\x18\x06 \x01(\t\x12\'\n\x07\x64\x61taset\x18\x07 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12\x0f\n\x07options\x18\x0c \x01(\tB\x11\n\x0f_failure_reason\"v\n\x03Job\x12\x30\n\x0bprofile_job\x18\x01 \x01(\x0b\x32\x19.tetra_hub.api.ProfileJobH\x00\x12\x36\n\x0evalidation_job\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ValidationJobH\x00\x42\x05\n\x03job\"T\n\x0eProfileJobList\x12\'\n\x04jobs\x18\x01 \x03(\x0b\x32\x19.tetra_hub.api.ProfileJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"Z\n\x11ValidationJobList\x12*\n\x04jobs\x18\x01 \x03(\x0b\x32\x1c.tetra_hub.api.ValidationJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\x07JobList\x12 \n\x04jobs\x18\x01 \x03(\x0b\x32\x12.tetra_hub.api.Job\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"j\n\x10ProfileJobResult\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x32\n\x07profile\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\n\n\x08_profile\"K\n\x13ValidationJobResult\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12\x19\n\x11output_dataset_id\x18\x02 \x01(\t\"\x99\x01\n\tJobResult\x12=\n\x12profile_job_result\x18\x01 \x01(\x0b\x32\x1f.tetra_hub.api.ProfileJobResultH\x00\x12\x43\n\x15validation_job_result\x18\x02 \x01(\x0b\x32\".tetra_hub.api.ValidationJobResultH\x00\x42\x08\n\x06result\"\xf4\x02\n\x08VizGraph\x12/\n\ngraph_type\x18\x01 \x01(\x0e\x32\x1b.tetra_hub.api.VizGraphType\x12-\n\tsubgraphs\x18\x03 \x03(\x0b\x32\x1a.tetra_hub.api.VizSubgraph\x12;\n\nparameters\x18\x04 \x03(\x0b\x32\'.tetra_hub.api.VizGraph.ParametersEntry\x12\x35\n\x07tensors\x18\x05 \x03(\x0b\x32$.tetra_hub.api.VizGraph.TensorsEntry\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\x1aH\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\'\n\x05value\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensor:\x02\x38\x01\"B\n\x0bVizSubgraph\x12\x0c\n\x04name\x18\x01 \x01(\t\x12%\n\x05nodes\x18\x02 \x03(\x0b\x32\x16.tetra_hub.api.VizNode\"\x17\n\x08VizShape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\"\x8c\x02\n\tVizTensor\x12&\n\x05\x64type\x18\x02 \x01(\x0e\x32\x17.tetra_hub.api.VizDtype\x12&\n\x05shape\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.VizShape\x12<\n\nparameters\x18\x04 \x03(\x0b\x32(.tetra_hub.api.VizTensor.ParametersEntry\x12%\n\x04\x64\x61ta\x18\x05 \x01(\x0b\x32\x17.tetra_hub.api.VizValue\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\"\x90\x02\n\x07VizNode\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06inputs\x18\x03 \x03(\t\x12\x0f\n\x07outputs\x18\x04 \x03(\t\x12\x12\n\ninput_keys\x18\x05 \x03(\t\x12\x13\n\x0boutput_keys\x18\x06 \x03(\t\x12:\n\nattributes\x18\x07 \x03(\x0b\x32&.tetra_hub.api.VizNode.AttributesEntry\x12\x10\n\x08subgraph\x18\x08 \x01(\x03\x1aN\n\x0f\x41ttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12*\n\x05value\x18\x02 \x01(\x0b\x32\x1b.tetra_hub.api.VizAttribute:\x02\x38\x01\"\xe0\x03\n\x08VizValue\x12\x17\n\rliteral_value\x18\x01 \x01(\tH\x00\x12\x16\n\x0cstring_value\x18\x02 \x01(\tH\x00\x12\x17\n\rinteger_value\x18\x03 \x01(\x03H\x00\x12\x15\n\x0b\x66loat_value\x18\x04 \x01(\x02H\x00\x12\x14\n\nbool_value\x18\x05 \x01(\x08H\x00\x12\x39\n\x0bstring_list\x18\x06 \x01(\x0b\x32\".tetra_hub.api.VizValue.StringListH\x00\x12;\n\x0cinteger_list\x18\x07 \x01(\x0b\x32#.tetra_hub.api.VizValue.IntegerListH\x00\x12\x37\n\nfloat_list\x18\x08 \x01(\x0b\x32!.tetra_hub.api.VizValue.FloatListH\x00\x12\x35\n\tbool_list\x18\t \x01(\x0b\x32 .tetra_hub.api.VizValue.BoolListH\x00\x1a\x1a\n\nStringList\x12\x0c\n\x04list\x18\x01 \x03(\t\x1a\x1b\n\x0bIntegerList\x12\x0c\n\x04list\x18\x01 \x03(\x03\x1a\x19\n\tFloatList\x12\x0c\n\x04list\x18\x01 \x03(\x02\x1a\x18\n\x08\x42oolList\x12\x0c\n\x04list\x18\x01 \x03(\x08\x42\x07\n\x05value\"l\n\x0cVizAttribute\x12(\n\x05value\x18\x01 \x01(\x0b\x32\x17.tetra_hub.api.VizValueH\x00\x12*\n\x06tensor\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensorH\x00\x42\x06\n\x04type\"\xfe\x01\n\x0bLayerDetail\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x17\n\x0flayer_type_name\x18\x03 \x01(\t\x12\n\n\x02id\x18\x04 \x01(\t\x12\x15\n\rdelegate_name\x18\x05 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x06 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x07 \x01(\x04H\x00\x88\x01\x01\x12\x17\n\nsegment_id\x18\x08 \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_execution_timeB\r\n\x0b_segment_id\"\xb1\x01\n\rSegmentDetail\x12\n\n\x02id\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x15\n\rdelegate_name\x18\x03 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x04 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x05 \x01(\x04H\x00\x88\x01\x01\x42\x11\n\x0f_execution_time\"%\n\x05Range\x12\r\n\x05lower\x18\x01 \x01(\x04\x12\r\n\x05upper\x18\x02 \x01(\x04\"\xef\x0b\n\rProfileDetail\x12\x16\n\x0e\x65xecution_time\x18\x01 \x01(\x04\x12\x19\n\x11peak_memory_usage\x18\x02 \x01(\x04\x12\x16\n\tload_time\x18\x03 \x01(\x04H\x00\x88\x01\x01\x12\x31\n\rlayer_details\x18\x04 \x03(\x0b\x32\x1a.tetra_hub.api.LayerDetail\x12\x15\n\rmajor_version\x18\x05 \x01(\x04\x12\x15\n\rminor_version\x18\x06 \x01(\x04\x12#\n\x1b\x61\x66ter_cold_load_peak_memory\x18\x07 \x01(\x04\x12!\n\x19\x61\x66ter_compile_peak_memory\x18\x08 \x01(\x04\x12#\n\x1b\x61\x66ter_execution_peak_memory\x18\t \x01(\x04\x12#\n\x1b\x61\x66ter_warm_load_peak_memory\x18\n \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_cold_load_current_memory\x18\x0b \x01(\x04\x12$\n\x1c\x62\x65\x66ore_cold_load_peak_memory\x18\x0c \x01(\x04\x12%\n\x1d\x62\x65\x66ore_compile_current_memory\x18\r \x01(\x04\x12\"\n\x1a\x62\x65\x66ore_compile_peak_memory\x18\x0e \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_execution_current_memory\x18\x0f \x01(\x04\x12$\n\x1c\x62\x65\x66ore_execution_peak_memory\x18\x10 \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_warm_load_current_memory\x18\x11 \x01(\x04\x12$\n\x1c\x62\x65\x66ore_warm_load_peak_memory\x18\x12 \x01(\x04\x12\x16\n\x0e\x63old_load_time\x18\x13 \x01(\x04\x12\x14\n\x0c\x63ompile_time\x18\x14 \x01(\x04\x12\x16\n\x0ewarm_load_time\x18\x15 \x01(\x04\x12&\n\x1e\x61\x66ter_cold_load_current_memory\x18\x16 \x01(\x04\x12&\n\x1e\x61\x66ter_warm_load_current_memory\x18\x17 \x01(\x04\x12$\n\x1c\x61\x66ter_compile_current_memory\x18\x18 \x01(\x04\x12&\n\x1e\x61\x66ter_execution_current_memory\x18\x19 \x01(\x04\x12\x45\n\x0e\x63ompile_memory\x18\x1a \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x01\x88\x01\x01\x12G\n\x10\x63old_load_memory\x18\x1b \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x02\x88\x01\x01\x12G\n\x10warm_load_memory\x18\x1c \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x03\x88\x01\x01\x12G\n\x10\x65xecution_memory\x18\x1d \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x04\x88\x01\x01\x12\x19\n\x11\x61ll_compile_times\x18\x1e \x03(\x04\x12\x1b\n\x13\x61ll_cold_load_times\x18\x1f \x03(\x04\x12\x1b\n\x13\x61ll_warm_load_times\x18  \x03(\x04\x12\x1b\n\x13\x61ll_execution_times\x18! \x03(\x04\x12\x35\n\x0fsegment_details\x18\" \x03(\x0b\x32\x1c.tetra_hub.api.SegmentDetail\x1aY\n\x0bMemoryUsage\x12&\n\x08increase\x18\x01 \x01(\x0b\x32\x14.tetra_hub.api.Range\x12\"\n\x04peak\x18\x02 \x01(\x0b\x32\x14.tetra_hub.api.RangeB\x0c\n\n_load_timeB\x11\n\x0f_compile_memoryB\x13\n\x11_cold_load_memoryB\x13\n\x11_warm_load_memoryB\x13\n\x11_execution_memory*\xd7\x01\n\x08JobState\x12\x19\n\x15JOB_STATE_UNSPECIFIED\x10\x00\x12\x12\n\x0eJOB_STATE_DONE\x10\n\x12\x14\n\x10JOB_STATE_FAILED\x10\x1e\x12\x1e\n\x1aJOB_STATE_OPTIMIZING_MODEL\x10\x32\x12!\n\x1dJOB_STATE_PROVISIONING_DEVICE\x10<\x12#\n\x1fJOB_STATE_MEASURING_PERFORMANCE\x10\x46\x12\x1e\n\x1aJOB_STATE_VALIDATING_MODEL\x10P*E\n\x0bTensorDtype\x12\x1c\n\x18TENSOR_DTYPE_UNSPECIFIED\x10\x00\x12\x18\n\x14TENSOR_DTYPE_FLOAT32\x10\x01*\xbb\x01\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16MODEL_TYPE_TORCHSCRIPT\x10\x01\x12\x16\n\x12MODEL_TYPE_MLMODEL\x10\x02\x12.\n*MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT\x10\x03\x12\x15\n\x11MODEL_TYPE_TFLITE\x10\x04\x12\x17\n\x13MODEL_TYPE_MLMODELC\x10\x05*T\n\x07JobType\x12\x18\n\x14JOB_TYPE_UNSPECIFIED\x10\x00\x12\x16\n\x12JOB_TYPE_PROFILING\x10\x01\x12\x17\n\x13JOB_TYPE_VALIDATION\x10\x02*\x83\x01\n\x0cVizGraphType\x12\x1e\n\x1aVIZ_GRAPH_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16VIZ_GRAPH_TYPE_MLMODEL\x10\x01\x12\x1c\n\x18VIZ_GRAPH_TYPE_MLPROGRAM\x10\x02\x12\x19\n\x15VIZ_GRAPH_TYPE_TFLITE\x10\n*\x8c\x05\n\x08VizDtype\x12\x19\n\x15VIZ_DTYPE_UNSPECIFIED\x10\x00\x12\x15\n\x11VIZ_DTYPE_FLOAT16\x10\x01\x12\x15\n\x11VIZ_DTYPE_FLOAT32\x10\x02\x12\x15\n\x11VIZ_DTYPE_FLOAT64\x10\x03\x12\x13\n\x0fVIZ_DTYPE_UINT8\x10\x04\x12\x12\n\x0eVIZ_DTYPE_INT8\x10\x05\x12\x14\n\x10VIZ_DTYPE_UINT16\x10\x06\x12\x13\n\x0fVIZ_DTYPE_INT16\x10\x07\x12\x14\n\x10VIZ_DTYPE_UINT32\x10\x08\x12\x13\n\x0fVIZ_DTYPE_INT32\x10\t\x12\x14\n\x10VIZ_DTYPE_UINT64\x10\n\x12\x13\n\x0fVIZ_DTYPE_INT64\x10\x0b\x12\x17\n\x13VIZ_DTYPE_COMPLEX64\x10\x0c\x12\x18\n\x14VIZ_DTYPE_COMPLEX128\x10\r\x12\x14\n\x10VIZ_DTYPE_STRING\x10\x0e\x12\x12\n\x0eVIZ_DTYPE_BOOL\x10\x0f\x12\x13\n\x0fVIZ_DTYPE_UINT1\x10\x32\x12\x13\n\x0fVIZ_DTYPE_UINT2\x10\x33\x12\x13\n\x0fVIZ_DTYPE_UINT3\x10\x34\x12\x13\n\x0fVIZ_DTYPE_UINT4\x10\x35\x12\x13\n\x0fVIZ_DTYPE_UINT5\x10\x36\x12\x13\n\x0fVIZ_DTYPE_UINT6\x10\x37\x12\x13\n\x0fVIZ_DTYPE_UINT7\x10\x38\x12#\n\x1fVIZ_DTYPE_DICT_INT64_TO_FLOAT64\x10\x64\x12$\n VIZ_DTYPE_DICT_STRING_TO_FLOAT64\x10\x65\x12\x1d\n\x19VIZ_DTYPE_TFLITE_RESOURCE\x10n\x12\x1c\n\x18VIZ_DTYPE_TFLITE_VARIANT\x10o*m\n\x0b\x43omputeUnit\x12\x1c\n\x18\x43OMPUTE_UNIT_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43OMPUTE_UNIT_CPU\x10\x01\x12\x14\n\x10\x43OMPUTE_UNIT_GPU\x10\x02\x12\x14\n\x10\x43OMPUTE_UNIT_NPU\x10\x03\x62\x06proto3')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1atetra_hub/public_api.proto\x12\rtetra_hub.api\x1a\x1fgoogle/protobuf/timestamp.proto\"\x9a\x01\n\x14\x43reateUpdateResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x31\n\rcreation_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x65xpiration_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"0\n\x0f\x46ileDownloadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x10\n\x08\x66ilename\x18\x02 \x01(\t\"\x9e\x01\n\rFileUploadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x17\n\x0f\x66ile_field_name\x18\x02 \x01(\t\x12\x38\n\x06\x66ields\x18\x03 \x03(\x0b\x32(.tetra_hub.api.FileUploadURL.FieldsEntry\x1a-\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"v\n\x04User\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x12\n\nfirst_name\x18\x02 \x01(\t\x12\x11\n\tlast_name\x18\x03 \x01(\t\x12\r\n\x05\x65mail\x18\x04 \x01(\t\x12\x12\n\x05token\x18\x05 \x01(\tH\x00\x88\x01\x01\x12\x0e\n\x06org_id\x18\x06 \x01(\x04\x42\x08\n\x06_token\"I\n\x08UserList\x12\"\n\x05users\x18\x01 \x03(\x0b\x32\x13.tetra_hub.api.User\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"@\n\x12UserChangePassword\x12\x14\n\x0cold_password\x18\x01 \x01(\t\x12\x14\n\x0cnew_password\x18\x02 \x01(\t\"V\n\x0cOrganization\x12\x0e\n\x06org_id\x18\x01 \x01(\x04\x12\x0c\n\x04name\x18\x02 \x01(\t\x12(\n\x07members\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.UserList\"6\n\x06\x44\x65vice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02os\x18\x02 \x01(\t\x12\x12\n\nattributes\x18\x03 \x03(\t\"O\n\nDeviceList\x12&\n\x07\x64\x65vices\x18\x01 \x03(\x0b\x32\x15.tetra_hub.api.Device\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xd4\x02\n\x07\x44\x61taset\x12\x17\n\ndataset_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x38\n\x0f\x65xpiration_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\r\n\x0b_dataset_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\x12\n\x10_expiration_timeB\x17\n\x15_file_upload_complete\"R\n\x0b\x44\x61tasetList\x12(\n\x08\x64\x61tasets\x18\x01 \x03(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\nTensorType\x12\r\n\x05shape\x18\x01 \x03(\x04\x12)\n\x05\x64type\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.TensorDtype\"O\n\x0fNamedTensorType\x12\x0c\n\x04name\x18\x01 \x01(\t\x12.\n\x0btensor_type\x18\x02 \x01(\x0b\x32\x19.tetra_hub.api.TensorType\"D\n\x13NamedTensorTypeList\x12-\n\x05types\x18\x01 \x03(\x0b\x32\x1e.tetra_hub.api.NamedTensorType\"\xc2\x02\n\x05Model\x12\x15\n\x08model_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x31\n\nmodel_type\x18\x05 \x01(\x0e\x32\x18.tetra_hub.api.ModelTypeH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\x0b\n\t_model_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\r\n\x0b_model_typeB\x17\n\x15_file_upload_complete\"L\n\tModelList\x12$\n\x06models\x18\x01 \x03(\x0b\x32\x14.tetra_hub.api.Model\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xa3\x07\n\nProfileJob\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12#\n\x05model\x18\x04 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12%\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12<\n\x10tensor_type_list\x18\x07 \x01(\x0b\x32\".tetra_hub.api.NamedTensorTypeList\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x65xecution_time\x18\x0b \x01(\x04H\x00\x88\x01\x01\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0c \x01(\tH\x01\x88\x01\x01\x12\x1e\n\x11peak_memory_usage\x18\r \x01(\x04H\x02\x88\x01\x01\x12\x0c\n\x04name\x18\x0e \x01(\t\x12\x0f\n\x07options\x18\x0f \x01(\t\x12\'\n\x07\x64\x61taset\x18\x10 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12/\n\x0ctarget_model\x18\x11 \x01(\x0b\x32\x14.tetra_hub.api.ModelH\x03\x88\x01\x01\x12\x38\n\x15\x65xecution_peak_memory\x18\x12 \x01(\x0b\x32\x14.tetra_hub.api.RangeH\x04\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\x13 \x01(\x08H\x05\x88\x01\x01\x12\x35\n\x11last_updated_time\x18\x14 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x15 \x01(\tH\x06\x88\x01\x01\x42\x11\n\x0f_execution_timeB\x11\n\x0f_failure_reasonB\x14\n\x12_peak_memory_usageB\x0f\n\r_target_modelB\x18\n\x16_execution_peak_memoryB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_url\"\xb2\x04\n\rValidationJob\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12#\n\x05model\x18\x03 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12%\n\x06\x64\x65vice\x18\x04 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12\x0c\n\x04name\x18\x06 \x01(\t\x12\'\n\x07\x64\x61taset\x18\x07 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12\x0f\n\x07options\x18\x0c \x01(\t\x12\x35\n\x11last_updated_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x0e \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0c\n\n_admin_url\"v\n\x03Job\x12\x30\n\x0bprofile_job\x18\x01 \x01(\x0b\x32\x19.tetra_hub.api.ProfileJobH\x00\x12\x36\n\x0evalidation_job\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ValidationJobH\x00\x42\x05\n\x03job\"T\n\x0eProfileJobList\x12\'\n\x04jobs\x18\x01 \x03(\x0b\x32\x19.tetra_hub.api.ProfileJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"Z\n\x11ValidationJobList\x12*\n\x04jobs\x18\x01 \x03(\x0b\x32\x1c.tetra_hub.api.ValidationJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\x07JobList\x12 \n\x04jobs\x18\x01 \x03(\x0b\x32\x12.tetra_hub.api.Job\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"j\n\x10ProfileJobResult\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x32\n\x07profile\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\n\n\x08_profile\"K\n\x13ValidationJobResult\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12\x19\n\x11output_dataset_id\x18\x02 \x01(\t\"\x99\x01\n\tJobResult\x12=\n\x12profile_job_result\x18\x01 \x01(\x0b\x32\x1f.tetra_hub.api.ProfileJobResultH\x00\x12\x43\n\x15validation_job_result\x18\x02 \x01(\x0b\x32\".tetra_hub.api.ValidationJobResultH\x00\x42\x08\n\x06result\"\xf4\x02\n\x08VizGraph\x12/\n\ngraph_type\x18\x01 \x01(\x0e\x32\x1b.tetra_hub.api.VizGraphType\x12-\n\tsubgraphs\x18\x03 \x03(\x0b\x32\x1a.tetra_hub.api.VizSubgraph\x12;\n\nparameters\x18\x04 \x03(\x0b\x32\'.tetra_hub.api.VizGraph.ParametersEntry\x12\x35\n\x07tensors\x18\x05 \x03(\x0b\x32$.tetra_hub.api.VizGraph.TensorsEntry\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\x1aH\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\'\n\x05value\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensor:\x02\x38\x01\"B\n\x0bVizSubgraph\x12\x0c\n\x04name\x18\x01 \x01(\t\x12%\n\x05nodes\x18\x02 \x03(\x0b\x32\x16.tetra_hub.api.VizNode\"\x17\n\x08VizShape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\"\x8c\x02\n\tVizTensor\x12&\n\x05\x64type\x18\x02 \x01(\x0e\x32\x17.tetra_hub.api.VizDtype\x12&\n\x05shape\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.VizShape\x12<\n\nparameters\x18\x04 \x03(\x0b\x32(.tetra_hub.api.VizTensor.ParametersEntry\x12%\n\x04\x64\x61ta\x18\x05 \x01(\x0b\x32\x17.tetra_hub.api.VizValue\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\"\x90\x02\n\x07VizNode\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06inputs\x18\x03 \x03(\t\x12\x0f\n\x07outputs\x18\x04 \x03(\t\x12\x12\n\ninput_keys\x18\x05 \x03(\t\x12\x13\n\x0boutput_keys\x18\x06 \x03(\t\x12:\n\nattributes\x18\x07 \x03(\x0b\x32&.tetra_hub.api.VizNode.AttributesEntry\x12\x10\n\x08subgraph\x18\x08 \x01(\x03\x1aN\n\x0f\x41ttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12*\n\x05value\x18\x02 \x01(\x0b\x32\x1b.tetra_hub.api.VizAttribute:\x02\x38\x01\"\xe0\x03\n\x08VizValue\x12\x17\n\rliteral_value\x18\x01 \x01(\tH\x00\x12\x16\n\x0cstring_value\x18\x02 \x01(\tH\x00\x12\x17\n\rinteger_value\x18\x03 \x01(\x03H\x00\x12\x15\n\x0b\x66loat_value\x18\x04 \x01(\x02H\x00\x12\x14\n\nbool_value\x18\x05 \x01(\x08H\x00\x12\x39\n\x0bstring_list\x18\x06 \x01(\x0b\x32\".tetra_hub.api.VizValue.StringListH\x00\x12;\n\x0cinteger_list\x18\x07 \x01(\x0b\x32#.tetra_hub.api.VizValue.IntegerListH\x00\x12\x37\n\nfloat_list\x18\x08 \x01(\x0b\x32!.tetra_hub.api.VizValue.FloatListH\x00\x12\x35\n\tbool_list\x18\t \x01(\x0b\x32 .tetra_hub.api.VizValue.BoolListH\x00\x1a\x1a\n\nStringList\x12\x0c\n\x04list\x18\x01 \x03(\t\x1a\x1b\n\x0bIntegerList\x12\x0c\n\x04list\x18\x01 \x03(\x03\x1a\x19\n\tFloatList\x12\x0c\n\x04list\x18\x01 \x03(\x02\x1a\x18\n\x08\x42oolList\x12\x0c\n\x04list\x18\x01 \x03(\x08\x42\x07\n\x05value\"l\n\x0cVizAttribute\x12(\n\x05value\x18\x01 \x01(\x0b\x32\x17.tetra_hub.api.VizValueH\x00\x12*\n\x06tensor\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensorH\x00\x42\x06\n\x04type\"\xfe\x01\n\x0bLayerDetail\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x17\n\x0flayer_type_name\x18\x03 \x01(\t\x12\n\n\x02id\x18\x04 \x01(\t\x12\x15\n\rdelegate_name\x18\x05 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x06 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x07 \x01(\x04H\x00\x88\x01\x01\x12\x17\n\nsegment_id\x18\x08 \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_execution_timeB\r\n\x0b_segment_id\"\xb1\x01\n\rSegmentDetail\x12\n\n\x02id\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x15\n\rdelegate_name\x18\x03 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x04 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x05 \x01(\x04H\x00\x88\x01\x01\x42\x11\n\x0f_execution_time\"%\n\x05Range\x12\r\n\x05lower\x18\x01 \x01(\x04\x12\r\n\x05upper\x18\x02 \x01(\x04\"\xef\x0b\n\rProfileDetail\x12\x16\n\x0e\x65xecution_time\x18\x01 \x01(\x04\x12\x19\n\x11peak_memory_usage\x18\x02 \x01(\x04\x12\x16\n\tload_time\x18\x03 \x01(\x04H\x00\x88\x01\x01\x12\x31\n\rlayer_details\x18\x04 \x03(\x0b\x32\x1a.tetra_hub.api.LayerDetail\x12\x15\n\rmajor_version\x18\x05 \x01(\x04\x12\x15\n\rminor_version\x18\x06 \x01(\x04\x12#\n\x1b\x61\x66ter_cold_load_peak_memory\x18\x07 \x01(\x04\x12!\n\x19\x61\x66ter_compile_peak_memory\x18\x08 \x01(\x04\x12#\n\x1b\x61\x66ter_execution_peak_memory\x18\t \x01(\x04\x12#\n\x1b\x61\x66ter_warm_load_peak_memory\x18\n \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_cold_load_current_memory\x18\x0b \x01(\x04\x12$\n\x1c\x62\x65\x66ore_cold_load_peak_memory\x18\x0c \x01(\x04\x12%\n\x1d\x62\x65\x66ore_compile_current_memory\x18\r \x01(\x04\x12\"\n\x1a\x62\x65\x66ore_compile_peak_memory\x18\x0e \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_execution_current_memory\x18\x0f \x01(\x04\x12$\n\x1c\x62\x65\x66ore_execution_peak_memory\x18\x10 \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_warm_load_current_memory\x18\x11 \x01(\x04\x12$\n\x1c\x62\x65\x66ore_warm_load_peak_memory\x18\x12 \x01(\x04\x12\x16\n\x0e\x63old_load_time\x18\x13 \x01(\x04\x12\x14\n\x0c\x63ompile_time\x18\x14 \x01(\x04\x12\x16\n\x0ewarm_load_time\x18\x15 \x01(\x04\x12&\n\x1e\x61\x66ter_cold_load_current_memory\x18\x16 \x01(\x04\x12&\n\x1e\x61\x66ter_warm_load_current_memory\x18\x17 \x01(\x04\x12$\n\x1c\x61\x66ter_compile_current_memory\x18\x18 \x01(\x04\x12&\n\x1e\x61\x66ter_execution_current_memory\x18\x19 \x01(\x04\x12\x45\n\x0e\x63ompile_memory\x18\x1a \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x01\x88\x01\x01\x12G\n\x10\x63old_load_memory\x18\x1b \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x02\x88\x01\x01\x12G\n\x10warm_load_memory\x18\x1c \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x03\x88\x01\x01\x12G\n\x10\x65xecution_memory\x18\x1d \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x04\x88\x01\x01\x12\x19\n\x11\x61ll_compile_times\x18\x1e \x03(\x04\x12\x1b\n\x13\x61ll_cold_load_times\x18\x1f \x03(\x04\x12\x1b\n\x13\x61ll_warm_load_times\x18  \x03(\x04\x12\x1b\n\x13\x61ll_execution_times\x18! \x03(\x04\x12\x35\n\x0fsegment_details\x18\" \x03(\x0b\x32\x1c.tetra_hub.api.SegmentDetail\x1aY\n\x0bMemoryUsage\x12&\n\x08increase\x18\x01 \x01(\x0b\x32\x14.tetra_hub.api.Range\x12\"\n\x04peak\x18\x02 \x01(\x0b\x32\x14.tetra_hub.api.RangeB\x0c\n\n_load_timeB\x11\n\x0f_compile_memoryB\x13\n\x11_cold_load_memoryB\x13\n\x11_warm_load_memoryB\x13\n\x11_execution_memory*\xd7\x01\n\x08JobState\x12\x19\n\x15JOB_STATE_UNSPECIFIED\x10\x00\x12\x12\n\x0eJOB_STATE_DONE\x10\n\x12\x14\n\x10JOB_STATE_FAILED\x10\x1e\x12\x1e\n\x1aJOB_STATE_OPTIMIZING_MODEL\x10\x32\x12!\n\x1dJOB_STATE_PROVISIONING_DEVICE\x10<\x12#\n\x1fJOB_STATE_MEASURING_PERFORMANCE\x10\x46\x12\x1e\n\x1aJOB_STATE_VALIDATING_MODEL\x10P*u\n\x0bTensorDtype\x12\x1c\n\x18TENSOR_DTYPE_UNSPECIFIED\x10\x00\x12\x18\n\x14TENSOR_DTYPE_FLOAT32\x10\x01\x12\x16\n\x12TENSOR_DTYPE_INT32\x10\x02\x12\x16\n\x12TENSOR_DTYPE_INT64\x10\x03*\xe4\x01\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16MODEL_TYPE_TORCHSCRIPT\x10\x01\x12\x16\n\x12MODEL_TYPE_MLMODEL\x10\x02\x12.\n*MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT\x10\x03\x12\x15\n\x11MODEL_TYPE_TFLITE\x10\x04\x12\x17\n\x13MODEL_TYPE_MLMODELC\x10\x05\x12\x13\n\x0fMODEL_TYPE_ONNX\x10\x06\x12\x12\n\x0eMODEL_TYPE_ORT\x10\x07*T\n\x07JobType\x12\x18\n\x14JOB_TYPE_UNSPECIFIED\x10\x00\x12\x16\n\x12JOB_TYPE_PROFILING\x10\x01\x12\x17\n\x13JOB_TYPE_VALIDATION\x10\x02*\x9c\x01\n\x0cVizGraphType\x12\x1e\n\x1aVIZ_GRAPH_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16VIZ_GRAPH_TYPE_MLMODEL\x10\x01\x12\x1c\n\x18VIZ_GRAPH_TYPE_MLPROGRAM\x10\x02\x12\x19\n\x15VIZ_GRAPH_TYPE_TFLITE\x10\n\x12\x17\n\x13VIZ_GRAPH_TYPE_ONNX\x10\x0b*\x8c\x05\n\x08VizDtype\x12\x19\n\x15VIZ_DTYPE_UNSPECIFIED\x10\x00\x12\x15\n\x11VIZ_DTYPE_FLOAT16\x10\x01\x12\x15\n\x11VIZ_DTYPE_FLOAT32\x10\x02\x12\x15\n\x11VIZ_DTYPE_FLOAT64\x10\x03\x12\x13\n\x0fVIZ_DTYPE_UINT8\x10\x04\x12\x12\n\x0eVIZ_DTYPE_INT8\x10\x05\x12\x14\n\x10VIZ_DTYPE_UINT16\x10\x06\x12\x13\n\x0fVIZ_DTYPE_INT16\x10\x07\x12\x14\n\x10VIZ_DTYPE_UINT32\x10\x08\x12\x13\n\x0fVIZ_DTYPE_INT32\x10\t\x12\x14\n\x10VIZ_DTYPE_UINT64\x10\n\x12\x13\n\x0fVIZ_DTYPE_INT64\x10\x0b\x12\x17\n\x13VIZ_DTYPE_COMPLEX64\x10\x0c\x12\x18\n\x14VIZ_DTYPE_COMPLEX128\x10\r\x12\x14\n\x10VIZ_DTYPE_STRING\x10\x0e\x12\x12\n\x0eVIZ_DTYPE_BOOL\x10\x0f\x12\x13\n\x0fVIZ_DTYPE_UINT1\x10\x32\x12\x13\n\x0fVIZ_DTYPE_UINT2\x10\x33\x12\x13\n\x0fVIZ_DTYPE_UINT3\x10\x34\x12\x13\n\x0fVIZ_DTYPE_UINT4\x10\x35\x12\x13\n\x0fVIZ_DTYPE_UINT5\x10\x36\x12\x13\n\x0fVIZ_DTYPE_UINT6\x10\x37\x12\x13\n\x0fVIZ_DTYPE_UINT7\x10\x38\x12#\n\x1fVIZ_DTYPE_DICT_INT64_TO_FLOAT64\x10\x64\x12$\n VIZ_DTYPE_DICT_STRING_TO_FLOAT64\x10\x65\x12\x1d\n\x19VIZ_DTYPE_TFLITE_RESOURCE\x10n\x12\x1c\n\x18VIZ_DTYPE_TFLITE_VARIANT\x10o*m\n\x0b\x43omputeUnit\x12\x1c\n\x18\x43OMPUTE_UNIT_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43OMPUTE_UNIT_CPU\x10\x01\x12\x14\n\x10\x43OMPUTE_UNIT_GPU\x10\x02\x12\x14\n\x10\x43OMPUTE_UNIT_NPU\x10\x03\x62\x06proto3')
 
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tetra_hub.public_api_pb2', globals())
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _FILEUPLOADURL_FIELDSENTRY._options = None
@@ -27,28 +27,28 @@
   _VIZGRAPH_PARAMETERSENTRY._serialized_options = b'8\001'
   _VIZGRAPH_TENSORSENTRY._options = None
   _VIZGRAPH_TENSORSENTRY._serialized_options = b'8\001'
   _VIZTENSOR_PARAMETERSENTRY._options = None
   _VIZTENSOR_PARAMETERSENTRY._serialized_options = b'8\001'
   _VIZNODE_ATTRIBUTESENTRY._options = None
   _VIZNODE_ATTRIBUTESENTRY._serialized_options = b'8\001'
-  _JOBSTATE._serialized_start=7615
-  _JOBSTATE._serialized_end=7830
-  _TENSORDTYPE._serialized_start=7832
-  _TENSORDTYPE._serialized_end=7901
-  _MODELTYPE._serialized_start=7904
-  _MODELTYPE._serialized_end=8091
-  _JOBTYPE._serialized_start=8093
-  _JOBTYPE._serialized_end=8177
-  _VIZGRAPHTYPE._serialized_start=8180
-  _VIZGRAPHTYPE._serialized_end=8311
-  _VIZDTYPE._serialized_start=8314
-  _VIZDTYPE._serialized_end=8966
-  _COMPUTEUNIT._serialized_start=8968
-  _COMPUTEUNIT._serialized_end=9077
+  _JOBSTATE._serialized_start=7801
+  _JOBSTATE._serialized_end=8016
+  _TENSORDTYPE._serialized_start=8018
+  _TENSORDTYPE._serialized_end=8135
+  _MODELTYPE._serialized_start=8138
+  _MODELTYPE._serialized_end=8366
+  _JOBTYPE._serialized_start=8368
+  _JOBTYPE._serialized_end=8452
+  _VIZGRAPHTYPE._serialized_start=8455
+  _VIZGRAPHTYPE._serialized_end=8611
+  _VIZDTYPE._serialized_start=8614
+  _VIZDTYPE._serialized_end=9266
+  _COMPUTEUNIT._serialized_start=9268
+  _COMPUTEUNIT._serialized_end=9377
   _CREATEUPDATERESPONSE._serialized_start=79
   _CREATEUPDATERESPONSE._serialized_end=233
   _FILEDOWNLOADURL._serialized_start=235
   _FILEDOWNLOADURL._serialized_end=283
   _FILEUPLOADURL._serialized_start=286
   _FILEUPLOADURL._serialized_end=444
   _FILEUPLOADURL_FIELDSENTRY._serialized_start=399
@@ -76,65 +76,65 @@
   _NAMEDTENSORTYPELIST._serialized_start=1512
   _NAMEDTENSORTYPELIST._serialized_end=1580
   _MODEL._serialized_start=1583
   _MODEL._serialized_end=1905
   _MODELLIST._serialized_start=1907
   _MODELLIST._serialized_end=1983
   _PROFILEJOB._serialized_start=1986
-  _PROFILEJOB._serialized_end=2824
-  _VALIDATIONJOB._serialized_start=2827
-  _VALIDATIONJOB._serialized_end=3296
-  _JOB._serialized_start=3298
-  _JOB._serialized_end=3416
-  _PROFILEJOBLIST._serialized_start=3418
-  _PROFILEJOBLIST._serialized_end=3502
-  _VALIDATIONJOBLIST._serialized_start=3504
-  _VALIDATIONJOBLIST._serialized_end=3594
-  _JOBLIST._serialized_start=3596
-  _JOBLIST._serialized_end=3666
-  _PROFILEJOBRESULT._serialized_start=3668
-  _PROFILEJOBRESULT._serialized_end=3774
-  _VALIDATIONJOBRESULT._serialized_start=3776
-  _VALIDATIONJOBRESULT._serialized_end=3851
-  _JOBRESULT._serialized_start=3854
-  _JOBRESULT._serialized_end=4007
-  _VIZGRAPH._serialized_start=4010
-  _VIZGRAPH._serialized_end=4382
-  _VIZGRAPH_PARAMETERSENTRY._serialized_start=4234
-  _VIZGRAPH_PARAMETERSENTRY._serialized_end=4308
-  _VIZGRAPH_TENSORSENTRY._serialized_start=4310
-  _VIZGRAPH_TENSORSENTRY._serialized_end=4382
-  _VIZSUBGRAPH._serialized_start=4384
-  _VIZSUBGRAPH._serialized_end=4450
-  _VIZSHAPE._serialized_start=4452
-  _VIZSHAPE._serialized_end=4475
-  _VIZTENSOR._serialized_start=4478
-  _VIZTENSOR._serialized_end=4746
-  _VIZTENSOR_PARAMETERSENTRY._serialized_start=4234
-  _VIZTENSOR_PARAMETERSENTRY._serialized_end=4308
-  _VIZNODE._serialized_start=4749
-  _VIZNODE._serialized_end=5021
-  _VIZNODE_ATTRIBUTESENTRY._serialized_start=4943
-  _VIZNODE_ATTRIBUTESENTRY._serialized_end=5021
-  _VIZVALUE._serialized_start=5024
-  _VIZVALUE._serialized_end=5504
-  _VIZVALUE_STRINGLIST._serialized_start=5387
-  _VIZVALUE_STRINGLIST._serialized_end=5413
-  _VIZVALUE_INTEGERLIST._serialized_start=5415
-  _VIZVALUE_INTEGERLIST._serialized_end=5442
-  _VIZVALUE_FLOATLIST._serialized_start=5444
-  _VIZVALUE_FLOATLIST._serialized_end=5469
-  _VIZVALUE_BOOLLIST._serialized_start=5471
-  _VIZVALUE_BOOLLIST._serialized_end=5495
-  _VIZATTRIBUTE._serialized_start=5506
-  _VIZATTRIBUTE._serialized_end=5614
-  _LAYERDETAIL._serialized_start=5617
-  _LAYERDETAIL._serialized_end=5871
-  _SEGMENTDETAIL._serialized_start=5874
-  _SEGMENTDETAIL._serialized_end=6051
-  _RANGE._serialized_start=6053
-  _RANGE._serialized_end=6090
-  _PROFILEDETAIL._serialized_start=6093
-  _PROFILEDETAIL._serialized_end=7612
-  _PROFILEDETAIL_MEMORYUSAGE._serialized_start=7427
-  _PROFILEDETAIL_MEMORYUSAGE._serialized_end=7516
+  _PROFILEJOB._serialized_end=2917
+  _VALIDATIONJOB._serialized_start=2920
+  _VALIDATIONJOB._serialized_end=3482
+  _JOB._serialized_start=3484
+  _JOB._serialized_end=3602
+  _PROFILEJOBLIST._serialized_start=3604
+  _PROFILEJOBLIST._serialized_end=3688
+  _VALIDATIONJOBLIST._serialized_start=3690
+  _VALIDATIONJOBLIST._serialized_end=3780
+  _JOBLIST._serialized_start=3782
+  _JOBLIST._serialized_end=3852
+  _PROFILEJOBRESULT._serialized_start=3854
+  _PROFILEJOBRESULT._serialized_end=3960
+  _VALIDATIONJOBRESULT._serialized_start=3962
+  _VALIDATIONJOBRESULT._serialized_end=4037
+  _JOBRESULT._serialized_start=4040
+  _JOBRESULT._serialized_end=4193
+  _VIZGRAPH._serialized_start=4196
+  _VIZGRAPH._serialized_end=4568
+  _VIZGRAPH_PARAMETERSENTRY._serialized_start=4420
+  _VIZGRAPH_PARAMETERSENTRY._serialized_end=4494
+  _VIZGRAPH_TENSORSENTRY._serialized_start=4496
+  _VIZGRAPH_TENSORSENTRY._serialized_end=4568
+  _VIZSUBGRAPH._serialized_start=4570
+  _VIZSUBGRAPH._serialized_end=4636
+  _VIZSHAPE._serialized_start=4638
+  _VIZSHAPE._serialized_end=4661
+  _VIZTENSOR._serialized_start=4664
+  _VIZTENSOR._serialized_end=4932
+  _VIZTENSOR_PARAMETERSENTRY._serialized_start=4420
+  _VIZTENSOR_PARAMETERSENTRY._serialized_end=4494
+  _VIZNODE._serialized_start=4935
+  _VIZNODE._serialized_end=5207
+  _VIZNODE_ATTRIBUTESENTRY._serialized_start=5129
+  _VIZNODE_ATTRIBUTESENTRY._serialized_end=5207
+  _VIZVALUE._serialized_start=5210
+  _VIZVALUE._serialized_end=5690
+  _VIZVALUE_STRINGLIST._serialized_start=5573
+  _VIZVALUE_STRINGLIST._serialized_end=5599
+  _VIZVALUE_INTEGERLIST._serialized_start=5601
+  _VIZVALUE_INTEGERLIST._serialized_end=5628
+  _VIZVALUE_FLOATLIST._serialized_start=5630
+  _VIZVALUE_FLOATLIST._serialized_end=5655
+  _VIZVALUE_BOOLLIST._serialized_start=5657
+  _VIZVALUE_BOOLLIST._serialized_end=5681
+  _VIZATTRIBUTE._serialized_start=5692
+  _VIZATTRIBUTE._serialized_end=5800
+  _LAYERDETAIL._serialized_start=5803
+  _LAYERDETAIL._serialized_end=6057
+  _SEGMENTDETAIL._serialized_start=6060
+  _SEGMENTDETAIL._serialized_end=6237
+  _RANGE._serialized_start=6239
+  _RANGE._serialized_end=6276
+  _PROFILEDETAIL._serialized_start=6279
+  _PROFILEDETAIL._serialized_end=7798
+  _PROFILEDETAIL_MEMORYUSAGE._serialized_start=7613
+  _PROFILEDETAIL_MEMORYUSAGE._serialized_end=7702
 # @@protoc_insertion_point(module_scope)
```

## tetra_hub/public_api_pb2.pyi

```diff
@@ -54,24 +54,28 @@
 class _TensorDtype:
     ValueType = typing.NewType('ValueType', builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 class _TensorDtypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_TensorDtype.ValueType], builtins.type):
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     TENSOR_DTYPE_UNSPECIFIED: _TensorDtype.ValueType  # 0
     TENSOR_DTYPE_FLOAT32: _TensorDtype.ValueType  # 1
+    TENSOR_DTYPE_INT32: _TensorDtype.ValueType  # 2
+    TENSOR_DTYPE_INT64: _TensorDtype.ValueType  # 3
 class TensorDtype(_TensorDtype, metaclass=_TensorDtypeEnumTypeWrapper):
     """----------
     /shape
     ----------
 
     """
     pass
 
 TENSOR_DTYPE_UNSPECIFIED: TensorDtype.ValueType  # 0
 TENSOR_DTYPE_FLOAT32: TensorDtype.ValueType  # 1
+TENSOR_DTYPE_INT32: TensorDtype.ValueType  # 2
+TENSOR_DTYPE_INT64: TensorDtype.ValueType  # 3
 global___TensorDtype = TensorDtype
 
 
 class _ModelType:
     ValueType = typing.NewType('ValueType', builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 class _ModelTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ModelType.ValueType], builtins.type):
@@ -82,14 +86,16 @@
     MODEL_TYPE_TORCHSCRIPT: _ModelType.ValueType  # 1
     MODEL_TYPE_MLMODEL: _ModelType.ValueType  # 2
     MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT: _ModelType.ValueType  # 3
     """unused"""
 
     MODEL_TYPE_TFLITE: _ModelType.ValueType  # 4
     MODEL_TYPE_MLMODELC: _ModelType.ValueType  # 5
+    MODEL_TYPE_ONNX: _ModelType.ValueType  # 6
+    MODEL_TYPE_ORT: _ModelType.ValueType  # 7
 class ModelType(_ModelType, metaclass=_ModelTypeEnumTypeWrapper):
     """-------------
     /models
     -------------
 
     """
     pass
@@ -100,14 +106,16 @@
 MODEL_TYPE_TORCHSCRIPT: ModelType.ValueType  # 1
 MODEL_TYPE_MLMODEL: ModelType.ValueType  # 2
 MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT: ModelType.ValueType  # 3
 """unused"""
 
 MODEL_TYPE_TFLITE: ModelType.ValueType  # 4
 MODEL_TYPE_MLMODELC: ModelType.ValueType  # 5
+MODEL_TYPE_ONNX: ModelType.ValueType  # 6
+MODEL_TYPE_ORT: ModelType.ValueType  # 7
 global___ModelType = ModelType
 
 
 class _JobType:
     ValueType = typing.NewType('ValueType', builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 class _JobTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_JobType.ValueType], builtins.type):
@@ -141,14 +149,17 @@
 
     VIZ_GRAPH_TYPE_MLPROGRAM: _VizGraphType.ValueType  # 2
     """Core ML (MIL representation)"""
 
     VIZ_GRAPH_TYPE_TFLITE: _VizGraphType.ValueType  # 10
     """Tensorflow"""
 
+    VIZ_GRAPH_TYPE_ONNX: _VizGraphType.ValueType  # 11
+    """ONNX"""
+
 class VizGraphType(_VizGraphType, metaclass=_VizGraphTypeEnumTypeWrapper):
     """VISUALIZATION //////////////////////////////////////////////
 
     Type of graph. Even though VizGraph is a generic graph representation,
     knowing the graph type gives the frontend the option to do customize
     a few things that are not stored the graph, such as:
      - Node coloring
@@ -168,14 +179,17 @@
 
 VIZ_GRAPH_TYPE_MLPROGRAM: VizGraphType.ValueType  # 2
 """Core ML (MIL representation)"""
 
 VIZ_GRAPH_TYPE_TFLITE: VizGraphType.ValueType  # 10
 """Tensorflow"""
 
+VIZ_GRAPH_TYPE_ONNX: VizGraphType.ValueType  # 11
+"""ONNX"""
+
 global___VizGraphType = VizGraphType
 
 
 class _VizDtype:
     ValueType = typing.NewType('ValueType', builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 class _VizDtypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_VizDtype.ValueType], builtins.type):
@@ -804,14 +818,16 @@
     PEAK_MEMORY_USAGE_FIELD_NUMBER: builtins.int
     NAME_FIELD_NUMBER: builtins.int
     OPTIONS_FIELD_NUMBER: builtins.int
     DATASET_FIELD_NUMBER: builtins.int
     TARGET_MODEL_FIELD_NUMBER: builtins.int
     EXECUTION_PEAK_MEMORY_FIELD_NUMBER: builtins.int
     HAS_VIZGRAPH_FIELD_NUMBER: builtins.int
+    LAST_UPDATED_TIME_FIELD_NUMBER: builtins.int
+    ADMIN_URL_FIELD_NUMBER: builtins.int
     profile_job_id: typing.Text
     @property
     def user(self) -> global___User: ...
     user_id: builtins.int
     @property
     def model(self) -> global___Model: ...
     job_state: global___JobState.ValueType
@@ -849,14 +865,21 @@
     @property
     def target_model(self) -> global___Model: ...
     @property
     def execution_peak_memory(self) -> global___Range: ...
     has_vizgraph: builtins.bool
     """True if the user should expect a non-404 response from /jobs/<id>/profile/vizgraph"""
 
+    @property
+    def last_updated_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
+        """The timestamp at which the job's state last changed"""
+        pass
+    admin_url: typing.Text
+    """The admin page URL for the job. Only populated if queried by a superuser."""
+
     def __init__(self,
         *,
         profile_job_id: typing.Text = ...,
         user: typing.Optional[global___User] = ...,
         user_id: builtins.int = ...,
         model: typing.Optional[global___Model] = ...,
         job_state: global___JobState.ValueType = ...,
@@ -870,17 +893,21 @@
         peak_memory_usage: typing.Optional[builtins.int] = ...,
         name: typing.Text = ...,
         options: typing.Text = ...,
         dataset: typing.Optional[global___Dataset] = ...,
         target_model: typing.Optional[global___Model] = ...,
         execution_peak_memory: typing.Optional[global___Range] = ...,
         has_vizgraph: typing.Optional[builtins.bool] = ...,
+        last_updated_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
+        admin_url: typing.Optional[typing.Text] = ...,
         ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["_execution_peak_memory",b"_execution_peak_memory","_execution_time",b"_execution_time","_failure_reason",b"_failure_reason","_has_vizgraph",b"_has_vizgraph","_peak_memory_usage",b"_peak_memory_usage","_target_model",b"_target_model","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","execution_peak_memory",b"execution_peak_memory","execution_time",b"execution_time","failure_reason",b"failure_reason","has_vizgraph",b"has_vizgraph","model",b"model","peak_memory_usage",b"peak_memory_usage","start_time",b"start_time","target_model",b"target_model","tensor_type_list",b"tensor_type_list","user",b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["_execution_peak_memory",b"_execution_peak_memory","_execution_time",b"_execution_time","_failure_reason",b"_failure_reason","_has_vizgraph",b"_has_vizgraph","_peak_memory_usage",b"_peak_memory_usage","_target_model",b"_target_model","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","execution_peak_memory",b"execution_peak_memory","execution_time",b"execution_time","failure_reason",b"failure_reason","has_vizgraph",b"has_vizgraph","job_state",b"job_state","model",b"model","name",b"name","options",b"options","peak_memory_usage",b"peak_memory_usage","profile_job_id",b"profile_job_id","start_time",b"start_time","target_model",b"target_model","tensor_type_list",b"tensor_type_list","user",b"user","user_id",b"user_id"]) -> None: ...
+    def HasField(self, field_name: typing_extensions.Literal["_admin_url",b"_admin_url","_execution_peak_memory",b"_execution_peak_memory","_execution_time",b"_execution_time","_failure_reason",b"_failure_reason","_has_vizgraph",b"_has_vizgraph","_peak_memory_usage",b"_peak_memory_usage","_target_model",b"_target_model","admin_url",b"admin_url","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","execution_peak_memory",b"execution_peak_memory","execution_time",b"execution_time","failure_reason",b"failure_reason","has_vizgraph",b"has_vizgraph","last_updated_time",b"last_updated_time","model",b"model","peak_memory_usage",b"peak_memory_usage","start_time",b"start_time","target_model",b"target_model","tensor_type_list",b"tensor_type_list","user",b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing_extensions.Literal["_admin_url",b"_admin_url","_execution_peak_memory",b"_execution_peak_memory","_execution_time",b"_execution_time","_failure_reason",b"_failure_reason","_has_vizgraph",b"_has_vizgraph","_peak_memory_usage",b"_peak_memory_usage","_target_model",b"_target_model","admin_url",b"admin_url","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","execution_peak_memory",b"execution_peak_memory","execution_time",b"execution_time","failure_reason",b"failure_reason","has_vizgraph",b"has_vizgraph","job_state",b"job_state","last_updated_time",b"last_updated_time","model",b"model","name",b"name","options",b"options","peak_memory_usage",b"peak_memory_usage","profile_job_id",b"profile_job_id","start_time",b"start_time","target_model",b"target_model","tensor_type_list",b"tensor_type_list","user",b"user","user_id",b"user_id"]) -> None: ...
+    @typing.overload
+    def WhichOneof(self, oneof_group: typing_extensions.Literal["_admin_url",b"_admin_url"]) -> typing.Optional[typing_extensions.Literal["admin_url"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_execution_peak_memory",b"_execution_peak_memory"]) -> typing.Optional[typing_extensions.Literal["execution_peak_memory"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_execution_time",b"_execution_time"]) -> typing.Optional[typing_extensions.Literal["execution_time"]]: ...
     @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_failure_reason",b"_failure_reason"]) -> typing.Optional[typing_extensions.Literal["failure_reason"]]: ...
     @typing.overload
@@ -908,14 +935,16 @@
     NAME_FIELD_NUMBER: builtins.int
     DATASET_FIELD_NUMBER: builtins.int
     CREATION_TIME_FIELD_NUMBER: builtins.int
     START_TIME_FIELD_NUMBER: builtins.int
     COMPLETION_TIME_FIELD_NUMBER: builtins.int
     FAILURE_REASON_FIELD_NUMBER: builtins.int
     OPTIONS_FIELD_NUMBER: builtins.int
+    LAST_UPDATED_TIME_FIELD_NUMBER: builtins.int
+    ADMIN_URL_FIELD_NUMBER: builtins.int
     validation_job_id: typing.Text
     """job identification"""
 
     @property
     def user(self) -> global___User:
         """unique user proto"""
         pass
@@ -949,31 +978,43 @@
     def completion_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
         """Job has completed"""
         pass
     failure_reason: typing.Text
     """failure reason"""
 
     options: typing.Text
+    @property
+    def last_updated_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
+        """The timestamp at which the job's state last changed"""
+        pass
+    admin_url: typing.Text
+    """The admin page URL for the job. Only populated if queried by a superuser."""
+
     def __init__(self,
         *,
         validation_job_id: typing.Text = ...,
         user: typing.Optional[global___User] = ...,
         model: typing.Optional[global___Model] = ...,
         device: typing.Optional[global___Device] = ...,
         job_state: global___JobState.ValueType = ...,
         name: typing.Text = ...,
         dataset: typing.Optional[global___Dataset] = ...,
         creation_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
         start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
         completion_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
         failure_reason: typing.Optional[typing.Text] = ...,
         options: typing.Text = ...,
+        last_updated_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
+        admin_url: typing.Optional[typing.Text] = ...,
         ) -> None: ...
-    def HasField(self, field_name: typing_extensions.Literal["_failure_reason",b"_failure_reason","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","failure_reason",b"failure_reason","model",b"model","start_time",b"start_time","user",b"user"]) -> builtins.bool: ...
-    def ClearField(self, field_name: typing_extensions.Literal["_failure_reason",b"_failure_reason","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","failure_reason",b"failure_reason","job_state",b"job_state","model",b"model","name",b"name","options",b"options","start_time",b"start_time","user",b"user","validation_job_id",b"validation_job_id"]) -> None: ...
+    def HasField(self, field_name: typing_extensions.Literal["_admin_url",b"_admin_url","_failure_reason",b"_failure_reason","admin_url",b"admin_url","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","failure_reason",b"failure_reason","last_updated_time",b"last_updated_time","model",b"model","start_time",b"start_time","user",b"user"]) -> builtins.bool: ...
+    def ClearField(self, field_name: typing_extensions.Literal["_admin_url",b"_admin_url","_failure_reason",b"_failure_reason","admin_url",b"admin_url","completion_time",b"completion_time","creation_time",b"creation_time","dataset",b"dataset","device",b"device","failure_reason",b"failure_reason","job_state",b"job_state","last_updated_time",b"last_updated_time","model",b"model","name",b"name","options",b"options","start_time",b"start_time","user",b"user","validation_job_id",b"validation_job_id"]) -> None: ...
+    @typing.overload
+    def WhichOneof(self, oneof_group: typing_extensions.Literal["_admin_url",b"_admin_url"]) -> typing.Optional[typing_extensions.Literal["admin_url"]]: ...
+    @typing.overload
     def WhichOneof(self, oneof_group: typing_extensions.Literal["_failure_reason",b"_failure_reason"]) -> typing.Optional[typing_extensions.Literal["failure_reason"]]: ...
 global___ValidationJob = ValidationJob
 
 class Job(google.protobuf.message.Message):
     """
     Get a job.
     GET /jobs/<id>
```

## tetra_hub/public_rest_api.py

```diff
@@ -1,45 +1,50 @@
 from __future__ import annotations
+
+import configparser
 import datetime
-import os
 import json
-import threading
-from typing import Any, Dict, List, Optional, Tuple
-from urllib.parse import urljoin, quote
+import mimetypes
+import os
 import posixpath
-import requests
-import configparser
-from tqdm import tqdm
+import shutil
+import tempfile
+import threading
 from contextlib import nullcontext
 from dataclasses import dataclass
+from pathlib import Path
 from types import SimpleNamespace
-from typing import List
+from typing import Any, Dict, List, Optional, Tuple, Union
+from urllib.parse import quote, urljoin
+from zipfile import ZipFile
+
 import numpy as np
+import requests
 from requests_toolbelt import MultipartEncoder, MultipartEncoderMonitor
-from . import public_api_pb2 as api_pb
+from tqdm import tqdm
+
 from . import api_status_codes
-from pathlib import Path
-import tempfile
-from zipfile import ZipFile
-import shutil
+from . import public_api_pb2 as api_pb
 
 UNKNOWN_ERROR = "Unknown error."
 API_VERSION = "v1"
 
 # Used for error message feedback
 CASUAL_CLASSNAMES = {
     api_pb.ProfileJob: "job",
     api_pb.Model: "model",
     api_pb.User: "user",
 }
 
 TETRA_CLIENT_ENV = "TETRA_CLIENT_INI"
 DEFAULT_CONFIG_PATH = "~/.tetra/client.ini"
 
-Shapes = Dict[str, Tuple[int, ...]]
+_InputSpec = Tuple[Tuple[int, ...], str]
+_InputSpecsList = List[Tuple[str, _InputSpec]]
+InputSpecs = Dict[str, Union[Tuple[int, ...], _InputSpec]]
 DatasetEntries = Dict[str, List[np.ndarray]]
 
 
 def get_config_path(expanduser=True):
     path = os.environ.get(TETRA_CLIENT_ENV, DEFAULT_CONFIG_PATH)
     if expanduser:
         path = os.path.expanduser(path)
@@ -121,14 +126,19 @@
         if class_name is not None:
             prefix = class_name.capitalize() + " "
 
         raise APIException(
             f"{prefix}ID {obj_id} could not be found. It may not exist or you may not have permission to view it.",
             status_code=response.status_code,
         )
+    elif response.status_code == api_status_codes.HTTP_403_FORBIDDEN:
+        raise APIException(
+            response.content,
+            status_code=response.status_code,
+        )
     else:
         raise APIException(status_code=response.status_code)
 
 
 def _prepare_offset_limit_query_list(offset: int, limit: Optional[int]) -> List[str]:
     extras = []
     if offset > 0:
@@ -213,46 +223,85 @@
         return json.loads(response.content)["key"]
     elif response.status_code == 400:
         raise ValueError("Failed to log in: Wrong Username / Password")
     else:
         raise APIException(status_code=response.status_code)
 
 
-def _create_named_tensor(name: str, shape: Tuple[int, ...]) -> api_pb.NamedTensorType:
+_STR_TO_TETRA_TYPE: Dict[str, api_pb.TensorDtype.ValueType] = {
+    "float32": api_pb.TensorDtype.TENSOR_DTYPE_FLOAT32,
+    "int32": api_pb.TensorDtype.TENSOR_DTYPE_INT32,
+    "int64": api_pb.TensorDtype.TENSOR_DTYPE_INT64,
+}
+_TETRA_TYPE_TO_STR: Dict[api_pb.TensorDtype.ValueType, str] = {
+    v: k for k, v in _STR_TO_TETRA_TYPE.items()
+}
+
+
+def _get_type_str_from_value(type: api_pb.TensorDtype.ValueType) -> str:
+    dtype = _TETRA_TYPE_TO_STR.get(type, None)
+    if dtype is None:
+        raise ValueError("Unknown tensor dtype")
+    return dtype
+
+
+def _get_type_vale_from_str(dtype: str) -> api_pb.TensorDtype.ValueType:
+    type = _STR_TO_TETRA_TYPE.get(dtype, None)
+    if type is None:
+        raise ValueError(
+            f"Unsupported tensor dtype={dtype}. Supported dtypes: {list(_STR_TO_TETRA_TYPE.keys())}"
+        )
+    return type
+
+
+def _create_named_tensor(
+    name: str, shape: Tuple[int, ...], type: str
+) -> api_pb.NamedTensorType:
     tensor_type_list = []
     for i in shape:
         tensor_type_list.append(i)
     tensor_type_pb = api_pb.TensorType(
-        shape=tensor_type_list, dtype=api_pb.TensorDtype.TENSOR_DTYPE_FLOAT32
+        shape=tensor_type_list, dtype=_get_type_vale_from_str(type)
     )
     return api_pb.NamedTensorType(name=name, tensor_type=tensor_type_pb)
 
 
 def _input_shapes_to_tensor_type_list_pb(
-    input_shapes: Shapes,
+    input_shapes: InputSpecs,
 ) -> api_pb.NamedTensorTypeList:
     tensor_type_pb_list = []
 
     if input_shapes is not None:
-        for name, shape in input_shapes.items():
-            named_tensor_type_pb = _create_named_tensor(name, shape)
+        for name, spec in input_shapes.items():
+            if isinstance(spec[0], tuple):
+                shape = spec[0]
+                dtype = spec[1]
+            else:
+                shape = spec  # type: ignore
+                dtype = "float32"
+
+            assert isinstance(dtype, str)
+            assert isinstance(shape, tuple)
+            named_tensor_type_pb = _create_named_tensor(name, shape, dtype)
             tensor_type_pb_list.append(named_tensor_type_pb)
 
     return api_pb.NamedTensorTypeList(types=tensor_type_pb_list)
 
 
 def _tensor_type_list_pb_to_list_shapes(
     tensor_type_list_pb: api_pb.NamedTensorTypeList,
-) -> List[Tuple[str, Tuple[int, ...]]]:
+) -> _InputSpecsList:
     shapes_list = []
     for named_tensor_type in tensor_type_list_pb.types:
         shape = []
         for d in named_tensor_type.tensor_type.shape:
             shape.append(d)
-        shapes_list.append((named_tensor_type.name, tuple(shape)))
+        dtype = named_tensor_type.tensor_type.dtype
+        type = _get_type_str_from_value(dtype)
+        shapes_list.append((named_tensor_type.name, (tuple(shape), type)))
     return shapes_list
 
 
 _get_unique_path_lock = threading.Lock()
 
 
 def _get_unique_path(dst_path: str) -> Tuple[str, str]:
@@ -277,36 +326,42 @@
 
 
 def _convert_inputs_to_tensor_type_list_pb(
     inputs: DatasetEntries,
 ) -> api_pb.NamedTensorTypeList:
     tensor_type_pb_list = []
     for name, tensor in inputs.items():
-        named_tensor_type_pb = _create_named_tensor(name, tensor[0].shape)
+        named_tensor_type_pb = _create_named_tensor(
+            name, tensor[0].shape, tensor[0].dtype.name
+        )
         tensor_type_pb_list.append(named_tensor_type_pb)
     return api_pb.NamedTensorTypeList(types=tensor_type_pb_list)
 
 
+def _input_shapes_dict_to_list(input_shapes: InputSpecs) -> _InputSpecsList:
+    return _tensor_type_list_pb_to_list_shapes(
+        _input_shapes_to_tensor_type_list_pb(input_shapes)
+    )
+
+
 def _do_input_shapes_match(
-    input_shapes: Shapes,
+    input_shapes: InputSpecs,
     tensor_type_list: api_pb.NamedTensorTypeList,
 ):
     inputs_tensor_type_list = _tensor_type_list_pb_to_list_shapes(tensor_type_list)
-    inputs_shapes_tensor_type_list = _tensor_type_list_pb_to_list_shapes(
-        _input_shapes_to_tensor_type_list_pb(input_shapes)
-    )
+    inputs_shapes_tensor_type_list = _input_shapes_dict_to_list(input_shapes)
 
     input_names_match = [False] * len(inputs_tensor_type_list)
-    for i, (input_name, input_tensor_shape) in enumerate(inputs_tensor_type_list):
-        for _, (input_shape_name, input_shape) in enumerate(
+    for i, (input_name, input_tensor_spec) in enumerate(inputs_tensor_type_list):
+        for _, (input_shape_name, input_spec) in enumerate(
             inputs_shapes_tensor_type_list
         ):
             if input_name == input_shape_name:
                 input_names_match[i] = True
-                if input_tensor_shape != input_shape:
+                if input_tensor_spec != input_spec:
                     return False
     return all(input_names_match)
 
 
 def _download_file(
     url: str, filename: str, dst_path: str, verbose: bool, extract_model: bool = False
 ) -> str:
@@ -397,15 +452,18 @@
     api_url=_api_url,
     input_shapes_to_tensor_type_list_pb=_input_shapes_to_tensor_type_list_pb,
     tensor_type_list_pb_to_list_shapes=_tensor_type_list_pb_to_list_shapes,
     get_unique_path=_get_unique_path,
     download_file=_download_file,
     convert_inputs_to_tensor_type_list_pb=_convert_inputs_to_tensor_type_list_pb,
     do_input_shapes_match=_do_input_shapes_match,
+    input_shapes_dict_to_list=_input_shapes_dict_to_list,
     quote_query_parameters=_quote_query_parameters,
+    get_type_str_from_value=_get_type_str_from_value,
+    get_type_vale_from_str=_get_type_vale_from_str,
 )
 
 
 def get_auth_user(config: ClientConfig) -> api_pb.User:
     """
     Get authenticated user information.
 
@@ -808,15 +866,20 @@
     # - immediately get some non-redirect response back
     #
     # In either case, the non-redirect response we recieve doesn't matter; it's thrown away.
     # response.url will be populated with the last URL the requests package tried.
     # This will be the redirected URL if applicable, or the original URL if there was no redirect.
     #
     with open(path, "rb") as asset_file:
-        fields[file_field_name] = ("model", asset_file, "application/octet-stream")
+        file_type, _ = mimetypes.guess_type(str(path))
+        fields[file_field_name] = (
+            "model",
+            asset_file,
+            file_type or "application/octet-stream",
+        )
         num_redirects = 0
         while True:
             asset_file.seek(0)
             mpe = MultipartEncoder(fields=fields)
             mpm = MultipartEncoderMonitor(mpe, update_progress)
             headers = {"content-type": mpm.content_type}
 
@@ -1413,15 +1476,14 @@
     return utils.download_file(response.url, response.filename, file_path, verbose)
 
 
 __all__ = [
     "utils",
     "APIException",
     "ClientConfig",
-    "Shapes",
     "get_auth_user",
     "get_user",
     "get_user_list",
     "get_dataset",
     "get_dataset_list",
     "get_device_list",
     "create_profile_job",
```

## tetra_hub/test/test_cli.py

```diff
@@ -1,11 +1,13 @@
+import configparser
+import tempfile
+
 import pytest
+
 from tetra_hub._cli import configure
-import tempfile
-import configparser
 
 
 @pytest.fixture
 def config_data():
     config_data = {
         "api": {
             "api_token": "API_TOKEN_fbajc",
```

## tetra_hub/test/test_client.py

```diff
@@ -1,16 +1,17 @@
-import pytest
 import shutil
 import tempfile
 from pathlib import Path
 
+import pytest
+
 from tetra_hub.client import (
+    UserError,
     _assert_is_valid_zipped_mlmodelc,
     _zip_mlmodelc_if_needed,
-    UserError,
 )
 
 
 def create_sample_mlmodelc(modelDir: Path):
     Path(modelDir).mkdir(parents=True)
     Path(modelDir / "model.espresso.net").touch()
     Path(modelDir / "model.espresso.shape").touch()
```

## tetra_hub/test/test_public_rest_api.py

```diff
@@ -1,9 +1,11 @@
-import pytest
 from unittest.mock import MagicMock
+
+import pytest
+
 import tetra_hub.public_rest_api as api
 
 OLD_APIT_RESUTS = None
 
 
 def setup_module(module):
     global OLD_APIT_RESUTS
```

## tetra_hub/util/dataset_entries_converters.py

```diff
@@ -1,10 +1,12 @@
+from typing import List
+
 import h5py
 import numpy as np
-from typing import List
+
 from tetra_hub.public_rest_api import DatasetEntries
 
 
 def _h5_data_to_np_array(h5f_input_data) -> List[np.ndarray]:
     """
     Converts a single h5 data point to an array or list of arrays.
     """
```

## Comparing `tetra_hub-0.6.0.dist-info/METADATA` & `tetra_hub-0.6.1.dist-info/METADATA`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tetra-hub
-Version: 0.6.0
+Version: 0.6.1
 Summary: Python API for Tetra Hub.
 Home-page: https://tetra.ai/
 Author: Tetra Intelligence Systems Inc.
 Author-email: support@tetra.ai
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: Development Status :: 2 - Pre-Alpha
@@ -25,14 +25,16 @@
 Requires-Dist: requests-toolbelt
 Requires-Dist: tqdm
 Requires-Dist: protobuf (<4,>=3.15)
 Requires-Dist: numpy (<2,>=1.22.0)
 Requires-Dist: h5py (<4,>=3.6.0)
 Provides-Extra: coremltools
 Requires-Dist: coremltools (==6.2) ; extra == 'coremltools'
+Provides-Extra: onnx
+Requires-Dist: onnx (==1.13.1) ; extra == 'onnx'
 Provides-Extra: torch
 Requires-Dist: torch (==1.13.1) ; extra == 'torch'
 Requires-Dist: torchvision (==0.14.1) ; extra == 'torch'
 
 Tetra Hub
 =========
```

## Comparing `tetra_hub-0.6.0.dist-info/RECORD` & `tetra_hub-0.6.1.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-tetra_hub/__init__.py,sha256=kZsbIw_fszBUmJiquQqZlZHZ0xnRGxyvgjyx2BVn-TA,272
-tetra_hub/_cli.py,sha256=99sFx8ywpxc063Wq_9ztA1Qrs5-2JZzEu5OYmErRrr4,3347
-tetra_hub/_version.py,sha256=cID1jLnC_vj48GgMN6Yb1FA3JsQ95zNmCHmRYE8TFhY,22
+tetra_hub/__init__.py,sha256=dypPlGFcYRNv21nwydpRPuw0Fut0_MlCs_OIRHhPc8Y,271
+tetra_hub/_cli.py,sha256=cHJuLXJa3dnbcM7BBeC3F0hrB1_7RN7uDV0uuFU9E8Q,3348
+tetra_hub/_version.py,sha256=baAcEjLSYFIeNZF51tOMmA_zAMhN8HvKael-UU-Ruec,22
 tetra_hub/api_status_codes.py,sha256=1Bo8lC_zSjBEz-bkEEZY8qfhrVRC-CfVOtVS77JOLGQ,4095
-tetra_hub/client.py,sha256=YG1-qb2--yfVqcCoSq03HSRX_uF6v71BgQxJwksPSHE,83174
+tetra_hub/client.py,sha256=8RwRU3cC-07byyLj9CTQOMSOV2HBnBqh6d4gFejrMP4,85881
 tetra_hub/hub.py,sha256=-FWdEz2KovD6MT9cn6CWOyPsxhyCcrld4XNjF-f52V4,949
-tetra_hub/public_api_pb2.py,sha256=885lmjs4d0GHG3lTztHrBUgNkR_VSmcS1rCkIGuqrDw,20914
-tetra_hub/public_api_pb2.pyi,sha256=SzWQBhlFjAk_s6JVO_UHyxphtnv384SSbn4nO0kYfUA,82690
-tetra_hub/public_rest_api.py,sha256=9A9zn1nbYbgwhc8fk08F_TMll0fa_KvplOyLuq3Pc28,43130
+tetra_hub/public_api_pb2.py,sha256=wNTHOYlEYXhYfEWPBKE7DXPdkqwA9qAu1lMwtxbtSLY,21421
+tetra_hub/public_api_pb2.pyi,sha256=xgPIZCs5ix2sQrM3p5YLGk1fRHQjuO_7w5NBV0vP8HM,84980
+tetra_hub/public_rest_api.py,sha256=PvbKQoO54U1CaiJsfzmC6PMBZyQSTQ5NAiBqe3JGNSk,45113
 tetra_hub/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tetra_hub/test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-tetra_hub/test/test_cli.py,sha256=VCnUmrpSCoHB3mZm1zZlt7XCzT3uUuhabxKnMGqxbKo,1584
-tetra_hub/test/test_client.py,sha256=dMeJAMlUACCkbxMqS16UqO3Zdirzb00pYsD3GcYalJc,3726
-tetra_hub/test/test_public_rest_api.py,sha256=TeUZJz2b3Y9ohoY3Njc0BEEdYUmRi2C2d8HApIJE2H8,599
+tetra_hub/test/test_cli.py,sha256=b84r92p0AR63M_w1WxpV9rkvCopdzKmXDt6cn2VFZ6A,1586
+tetra_hub/test/test_client.py,sha256=WawrN2qogNCYJt4F3Rv8GUTHS4A2dR7nuARx-IYZx1g,3727
+tetra_hub/test/test_public_rest_api.py,sha256=v_BjT53XOP9TZNFufWytEZb16cFKm9z90Oms9A0AEhY,601
 tetra_hub/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-tetra_hub/util/dataset_entries_converters.py,sha256=UaYP04VGsrQY8tsG2J-C_eEfIpLqOGEDOlVNwqo9QdA,3885
-tetra_hub-0.6.0.dist-info/METADATA,sha256=uDIIp0qaCOoIMQVsvzdQQNGdWD2GNJDza-pe6PmKNFI,2618
-tetra_hub-0.6.0.dist-info/WHEEL,sha256=00yskusixUoUt5ob_CiUp6LsnN5lqzTJpoqOFg_FVIc,92
-tetra_hub-0.6.0.dist-info/entry_points.txt,sha256=EuYMlBUJNBh51LZtTvw4XSjrMuOHZsq23X8CtQvzCb4,51
-tetra_hub-0.6.0.dist-info/top_level.txt,sha256=cVzWAT5ht1JM3K_TxfxGQcVyvGQZGaJw_ddkLgN8ulY,10
-tetra_hub-0.6.0.dist-info/RECORD,,
+tetra_hub/util/dataset_entries_converters.py,sha256=203V0O7NXA3ZCUUB9EB1oyaMViJwJfjfUYresCW9Ikk,3887
+tetra_hub-0.6.1.dist-info/METADATA,sha256=e1N2DNhyoBsgijsnpb5ad7CjwtJJ-cgzj32TSNe0nf8,2688
+tetra_hub-0.6.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+tetra_hub-0.6.1.dist-info/entry_points.txt,sha256=EuYMlBUJNBh51LZtTvw4XSjrMuOHZsq23X8CtQvzCb4,51
+tetra_hub-0.6.1.dist-info/top_level.txt,sha256=cVzWAT5ht1JM3K_TxfxGQcVyvGQZGaJw_ddkLgN8ulY,10
+tetra_hub-0.6.1.dist-info/RECORD,,
```

